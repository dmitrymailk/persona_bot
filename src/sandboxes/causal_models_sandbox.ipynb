{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Download configuration from huggingface.co and cache.\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hi, what is your name?\\n\\nI'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University of California, Berkeley. I'm a student at the University\",\n",
       " 'My name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is John.The name is']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "text = tokenizer.batch_encode_plus(\n",
    "    [\"Hi, what is your name?\", \"My name is John.\"], \n",
    "    return_tensors=\"pt\", \n",
    "    add_special_tokens=True,\n",
    "    padding=True,\n",
    ")\n",
    "# text = {'input_ids': torch.tensor([[2061,  318,  534, 1438,   30]]), 'attention_mask': torch.tensor([[1, 1, 1, 1, 1]])}\n",
    "# text['input_ids'] = tensor([[   0, 2264,   16,  110,  766,  116 ]])\n",
    "# text['attention_mask'] = tensor([[1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "generated_tokens = model.generate(\n",
    "\t**text,\n",
    "\tmax_length=100,\n",
    ")\n",
    "input_shape = text['input_ids'].shape\n",
    "# tokenizer.decode(generated_tokens[0], skip_special_tokens=False)\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[792,   6,  44,  24,  66, 193,  20],\n",
       "        [ 42, 193,  24, 356,   3,   3,   3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = text['input_ids'].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8718,  1197,  1197,  1197,  2275,  1197,  1197, 13063,  1197, 13063,\n",
       "        13063,  2275, 13063, 13063, 13063,  8201, 13063, 13063,  5995, 13063,\n",
       "        13063,  2229, 13063, 13063,  4248, 13063, 13063,  1197,  5995, 13063,\n",
       "         2229,  5995, 13063,  5995,  2229, 13063,  2229,  2229, 13063,  5995,\n",
       "         5995, 13063,     3, 13063, 13063,   222, 13063, 13063,  2496, 13063,\n",
       "        13063,  4032, 13063, 13063,     3,  2229,  2229,  5995,  2229,  2229,\n",
       "         2229,     3, 13063,  2229,  2496, 13063,  2229,     3,  2229, 13063,\n",
       "         2496,  2229,  2229,  2496,  2229, 13063,  4032,  2229,  2229,  2275,\n",
       "        13063,  2229,   222,  2229,  2229,  4032,  2229, 13063,     3,  5995,\n",
       "         2229,  5995,     2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens[0][input_shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' world'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hello world\"[len(\"hello\"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"hello what are doing today ?\", \"i am good , i just got off work and tired , i have two jobs .\", \"i just got done watching a horror movie\", \"i rather read , i've read about 20 books this year .\", \"wow ! i do love a good horror movie . loving this cooler weather\", \"but a good movie is always good .\", \"yes ! my son is in junior high and i just started letting him watch them too\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello what are doing today ?', 'i am good , i just got off work and tired , i have two jobs .', 'i just got done watching a horror movie', \"i rather read , i've read about 20 books this year .\", 'wow ! i do love a good horror movie . loving this cooler weather', 'but a good movie is always good .', 'yes ! my son is in junior high and i just started letting him watch them too']\n"
     ]
    }
   ],
   "source": [
    "print([\"hello what are doing today ?\", \"i am good , i just got off work and tired , i have two jobs .\", \"i just got done watching a horror movie\", \"i rather read , i've read about 20 books this year .\", \"wow ! i do love a good horror movie . loving this cooler weather\", \"but a good movie is always good .\", \"yes ! my son is in junior high and i just started letting him watch them too\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"hello what are doing today ?\", \"i am good , i just got off work and tired , i have two jobs .\", \"i just got done watching a horror movie\", \"i rather read , i've read about 20 books this year .\", \"wow ! i do love a good horror movie . loving this cooler weather\", \"but a good movie is always good .\", \"yes ! my son is in junior high and i just started letting him watch them too\", \"i work in the movies as well .\", \"neat ! ! i used to work in the human services field\", \"yes it is neat , i stunt double , it is so much fun and hard work .\", \"yes i bet you can get hurt . my wife works and i stay at home\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2, проверяю длину входных последовательностей среди всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_models_list = [\n",
    "\t\"gpt2\",\n",
    "\t\"microsoft/DialoGPT-medium\",\n",
    "\t\"RUCAIBox/mvp\",\n",
    "\t\"roberta-base\",\n",
    "\t\"facebook/blenderbot_small-90M\",\n",
    "\t\"facebook/bart-base\",\n",
    "\t\"google/bigbird-pegasus-large-arxiv\",\n",
    "\t\"facebook/blenderbot-400M-distill\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimweb/Desktop/deeppavlov/d_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    ")\n",
    "\n",
    "tokens = [\n",
    "\t\"<с_sep>\",\n",
    "\t\"<p_sep>\",\n",
    "\t\"<chat>\",\n",
    "\t\"<persona>\",\n",
    "]\n",
    "\n",
    "tokenizer.add_tokens(tokens, special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50258, 50257, 50259, 50260]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<с_sep><p_sep><chat><persona>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(special_tokens, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(special_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"<persona>Hello, how are you?<p_sep> persona_fact[1] <p_sep> persona_fact[2] <p_sep> persona_fact[3] <p_sep> persona_fact[4] <p_sep> <chat> реплика[-6] <с_sep> реплика[-5] <с_sep> реплика[-4] <с_sep> реплика[-3] <с_sep> реплика[-2] <с_sep> реплика[-1] <с_sep>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, how are you? persona_fact[1]  persona_fact[2]  persona_fact[3]  persona_fact[4]   реплика[-6]  реплика[-5]  реплика[-4]  реплика[-3]  реплика[-2]  реплика[-1] '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(input_text)['input_ids'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('d_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47eeeae5f0593d6ff7164e36f6d45daaa118b41372aa3e9757d1f066e1c76d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
