{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dt.fread(\"/home/dilyara.baymurzina/markov_dataset/train_markov.csv\")\n",
    "# dataset.to_jay(\"./datasets/russian_chats/train_markov.jay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = \"/home/dilyara.baymurzina/markov_dataset/preprocessed_ru_convers_tokenized.txt\"\n",
    "part_dataset = \"./datasets/russian_chats/part_markov.txt\"\n",
    "dataset_size = 10000\n",
    "with open(part_dataset, 'w') as part_dataset:\n",
    "    with open(original_path, 'r') as original_dataset:\n",
    "        part_dataset_str = \"\".join([next(original_dataset) for _ in range(dataset_size)])\n",
    "        part_dataset.write(part_dataset_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8152041, 0.667545)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('tinkoff-ai/response-quality-classifier-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('tinkoff-ai/response-quality-classifier-large')\n",
    "inputs = tokenizer('[CLS]привет[SEP]привет![SEP]как дела?[RESPONSE_TOKEN]великолепно, просто охуительно, лучше не куда, а у тебя?', max_length=514, add_special_tokens=False, return_tensors='pt')\n",
    "with torch.inference_mode():\n",
    "    logits = model(**inputs).logits\n",
    "    probas = torch.sigmoid(logits)[0].cpu().detach().numpy()\n",
    "relevance, specificity = probas\n",
    "relevance, specificity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceRanker:\n",
    "    def __init__(self, model_name='tinkoff-ai/response-quality-classifier-large'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    \n",
    "    def rank(self, context, response):\n",
    "        history = \"[SEP]\".join(context)\n",
    "        input_string = f'[CLS]{history}[RESPONSE_TOKEN]{response}'\n",
    "        inputs = self.tokenizer(\n",
    "            input_string, \n",
    "            max_length=512, \n",
    "            add_special_tokens=False, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        with torch.inference_mode():\n",
    "            logits = self.model(**inputs).logits\n",
    "            probas = torch.sigmoid(logits)[0].cpu().detach().numpy()\n",
    "        relevance, specificity = probas\n",
    "        return relevance, input_string\n",
    "\n",
    "relevance_ranker = RelevanceRanker()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dialogues into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dialog_1 = \"\"\"\n",
    "Ну , вообще – то , голосовые команды наверняка дублировались жестами .\n",
    "Так что небольшой обман в видео все – таки есть .\n",
    "простите , вы кинолог ?\n",
    "Хотя бы личную собаку дрессировали ?\n",
    "Знаете зачем жесты показывают вместе с командой ?\n",
    "Вовсе не потому , что собака не понимает слов .\n",
    "У моего друга была овчарка , которую он нашел на улице .\n",
    "Сам он ничего не знал о дрессуре .\n",
    "Просто разговаривал с ней , как с человеком и она делала то , что он просит .\n",
    "Пруф ?\n",
    "Никакого .\n",
    "Давно это было .\n",
    "Даже видеокамеры в те времена мало у кого были .\n",
    "А сама Айна уже умерла .\n",
    "И сын ее Чак , помер .\n",
    "Однажды я захотел проверить , в самом деле Айна понимает слова человеческие или ориентируется на интонацию или что – то еще .\n",
    "Я пришел в гараж , который она охраняла ночью и увидел , что она меня не дождалась и сделала кучу .\n",
    "Я стал гладить ее и ласково говорить : — \" Айна , а кто это у нас тут насрал ?\"\n",
    "Услышав последнее слово , она в страхе припала к полу и стала заползать под машину , ожидая наказания .\n",
    "Так я убедился , что она воспринимает именно само слово , а не жесты или интонацию голоса .\n",
    "Потом я сам заводил собак и узнал , что это действительно так .\n",
    "Собаки запоминают слова и даже отличают очень похожие .\n",
    "Последняя моя собака могла отличать , когда я обращаюсь к ней , а когда рассказываю кому – то про нее в контексте .\n",
    "То есть не реагировала на свое имя , если я просто говорю про нее , а не обращаюсь к ней .\n",
    "\"\"\"\n",
    "\n",
    "original_dialog_1_manual = \"\"\"\n",
    "Ну , вообще – то , голосовые команды наверняка дублировались жестами . Так что небольшой обман в видео все – таки есть .\n",
    "\n",
    "Простите , вы кинолог ? Хотя бы личную собаку дрессировали ? Знаете зачем жесты показывают вместе с командой ? Вовсе не потому , что собака не понимает слов . У моего друга была овчарка , которую он нашел на улице . Сам он ничего не знал о дрессуре . Просто разговаривал с ней , как с человеком и она делала то , что он просит .\n",
    "\n",
    "Пруф ? \n",
    "\n",
    "Никакого . Давно это было . Даже видеокамеры в те времена мало у кого были . А сама Айна уже умерла . И сын ее Чак , помер . Однажды я захотел проверить , в самом деле Айна понимает слова человеческие или ориентируется на интонацию или что – то еще . Я пришел в гараж , который она охраняла ночью и увидел , что она меня не дождалась и сделала кучу . Я стал гладить ее и ласково говорить : — \" Айна , а кто это у нас тут насрал ?\" Услышав последнее слово , она в страхе припала к полу и стала заползать под машину , ожидая наказания . Так я убедился , что она воспринимает именно само слово , а не жесты или интонацию голоса . Потом я сам заводил собак и узнал , что это действительно так . Собаки запоминают слова и даже отличают очень похожие . Последняя моя собака могла отличать , когда я обращаюсь к ней , а когда рассказываю кому – то про нее в контексте . То есть не реагировала на свое имя , если я просто говорю про нее , а не обращаюсь к ней .\n",
    "\"\"\"\n",
    "\n",
    "original_dialog_2 = \"\"\"\n",
    "А я считаю , очень правильно .\n",
    "Я вообще не понимаю , почему на работу , например , могут отказать женщине 26 – 35 лет , если у неё нет детей .\n",
    "Должны рассматривать всех и выбирать уже , исходя из профессиональных качеств , а не смотреть сколько детей , какой национальности и пола .\n",
    "Хотя бы из – за того , что она не сможет упаковать 46 \" ящик и выдать покупателю .\n",
    "Почему не сможет ?\n",
    "Да пофиг .\n",
    "По КЗОТу вроде не более 10 кг .\n",
    "Иначе нарушение закона работодателем .\n",
    "\"\"\"\n",
    "\n",
    "original_dialog_2_manual = \"\"\"\n",
    "А я считаю , очень правильно . \n",
    "Я вообще не понимаю , почему на работу , например , могут отказать женщине 26 – 35 лет , если у неё нет детей . Должны рассматривать всех и выбирать уже , исходя из профессиональных качеств , а не смотреть сколько детей , какой национальности и пола .\n",
    "Хотя бы из – за того , что она не сможет упаковать 46 \" ящик и выдать покупателю .\n",
    "Да пофиг .\n",
    "По КЗОТу вроде не более 10 кг . Иначе нарушение закона работодателем .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_STRING: [CLS]А я считаю , очень правильно .[RESPONSE_TOKEN]Я вообще не понимаю , почему на работу , например , могут отказать женщине 26 – 35 лет , если у неё нет детей .\n",
      "RELEVANCE: 0.9085078239440918\n",
      "\n",
      "INPUT_STRING: [CLS]Я вообще не понимаю , почему на работу , например , могут отказать женщине 26 – 35 лет , если у неё нет детей .[RESPONSE_TOKEN]Должны рассматривать всех и выбирать уже , исходя из профессиональных качеств , а не смотреть сколько детей , какой национальности и пола .\n",
      "RELEVANCE: 0.9774068593978882\n",
      "\n",
      "INPUT_STRING: [CLS]Должны рассматривать всех и выбирать уже , исходя из профессиональных качеств , а не смотреть сколько детей , какой национальности и пола .[RESPONSE_TOKEN]Хотя бы из – за того , что она не сможет упаковать 46 \" ящик и выдать покупателю .\n",
      "RELEVANCE: 0.8563143014907837\n",
      "\n",
      "INPUT_STRING: [CLS]Хотя бы из – за того , что она не сможет упаковать 46 \" ящик и выдать покупателю .[RESPONSE_TOKEN]Почему не сможет ?\n",
      "RELEVANCE: 0.9779601693153381\n",
      "\n",
      "INPUT_STRING: [CLS]Почему не сможет ?[RESPONSE_TOKEN]Да пофиг .\n",
      "RELEVANCE: 0.5370252132415771\n",
      "\n",
      "INPUT_STRING: [CLS]Да пофиг .[RESPONSE_TOKEN]По КЗОТу вроде не более 10 кг .\n",
      "RELEVANCE: 0.05385909974575043\n",
      "\n",
      "INPUT_STRING: [CLS]По КЗОТу вроде не более 10 кг .[RESPONSE_TOKEN]Иначе нарушение закона работодателем .\n",
      "RELEVANCE: 0.9702759385108948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialog = [item for item in original_dialog_2.split('\\n') if item]\n",
    "dialog_len = 1\n",
    "temp_dialog_len = 0\n",
    "for i in range(dialog_len, len(dialog) - dialog_len+1):\n",
    "    part = dialog[i - dialog_len:i + dialog_len]\n",
    "    context = part[:dialog_len]\n",
    "    response = part[-1]\n",
    "    # print(\"@@@\".join(part))\n",
    "    # print(context)\n",
    "    # print(response)\n",
    "    relevance, input_string = relevance_ranker.rank(context, response)\n",
    "    print(F\"INPUT_STRING: {input_string}\")\n",
    "    print(f\"RELEVANCE: {relevance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_STRING: [CLS]Ну , вообще – то , голосовые команды наверняка дублировались жестами .[RESPONSE_TOKEN]Так что небольшой обман в видео все – таки есть .\n",
      "RELEVANCE: 0.9836452007293701\n",
      "\n",
      "INPUT_STRING: [CLS]Так что небольшой обман в видео все – таки есть .[RESPONSE_TOKEN]простите , вы кинолог ?\n",
      "RELEVANCE: 0.8198174834251404\n",
      "\n",
      "INPUT_STRING: [CLS]простите , вы кинолог ?[RESPONSE_TOKEN]Хотя бы личную собаку дрессировали ?\n",
      "RELEVANCE: 0.7496459484100342\n",
      "\n",
      "INPUT_STRING: [CLS]Хотя бы личную собаку дрессировали ?[RESPONSE_TOKEN]Знаете зачем жесты показывают вместе с командой ?\n",
      "RELEVANCE: 0.3005693554878235\n",
      "\n",
      "INPUT_STRING: [CLS]Знаете зачем жесты показывают вместе с командой ?[RESPONSE_TOKEN]Вовсе не потому , что собака не понимает слов .\n",
      "RELEVANCE: 0.9718955159187317\n",
      "\n",
      "INPUT_STRING: [CLS]Вовсе не потому , что собака не понимает слов .[RESPONSE_TOKEN]У моего друга была овчарка , которую он нашел на улице .\n",
      "RELEVANCE: 0.5639684796333313\n",
      "\n",
      "INPUT_STRING: [CLS]У моего друга была овчарка , которую он нашел на улице .[RESPONSE_TOKEN]Сам он ничего не знал о дрессуре .\n",
      "RELEVANCE: 0.7201182842254639\n",
      "\n",
      "INPUT_STRING: [CLS]Сам он ничего не знал о дрессуре .[RESPONSE_TOKEN]Просто разговаривал с ней , как с человеком и она делала то , что он просит .\n",
      "RELEVANCE: 0.9760714769363403\n",
      "\n",
      "INPUT_STRING: [CLS]Просто разговаривал с ней , как с человеком и она делала то , что он просит .[RESPONSE_TOKEN]Пруф ?\n",
      "RELEVANCE: 0.3662819266319275\n",
      "\n",
      "INPUT_STRING: [CLS]Пруф ?[RESPONSE_TOKEN]Никакого .\n",
      "RELEVANCE: 0.45534440875053406\n",
      "\n",
      "INPUT_STRING: [CLS]Никакого .[RESPONSE_TOKEN]Давно это было .\n",
      "RELEVANCE: 0.11402197927236557\n",
      "\n",
      "INPUT_STRING: [CLS]Давно это было .[RESPONSE_TOKEN]Даже видеокамеры в те времена мало у кого были .\n",
      "RELEVANCE: 0.9288167953491211\n",
      "\n",
      "INPUT_STRING: [CLS]Даже видеокамеры в те времена мало у кого были .[RESPONSE_TOKEN]А сама Айна уже умерла .\n",
      "RELEVANCE: 0.03037736564874649\n",
      "\n",
      "INPUT_STRING: [CLS]А сама Айна уже умерла .[RESPONSE_TOKEN]И сын ее Чак , помер .\n",
      "RELEVANCE: 0.956544041633606\n",
      "\n",
      "INPUT_STRING: [CLS]И сын ее Чак , помер .[RESPONSE_TOKEN]Однажды я захотел проверить , в самом деле Айна понимает слова человеческие или ориентируется на интонацию или что – то еще .\n",
      "RELEVANCE: 0.07484447956085205\n",
      "\n",
      "INPUT_STRING: [CLS]Однажды я захотел проверить , в самом деле Айна понимает слова человеческие или ориентируется на интонацию или что – то еще .[RESPONSE_TOKEN]Я пришел в гараж , который она охраняла ночью и увидел , что она меня не дождалась и сделала кучу .\n",
      "RELEVANCE: 0.4777631163597107\n",
      "\n",
      "INPUT_STRING: [CLS]Я пришел в гараж , который она охраняла ночью и увидел , что она меня не дождалась и сделала кучу .[RESPONSE_TOKEN]Я стал гладить ее и ласково говорить : — \" Айна , а кто это у нас тут насрал ?\"\n",
      "RELEVANCE: 0.9629704356193542\n",
      "\n",
      "INPUT_STRING: [CLS]Я стал гладить ее и ласково говорить : — \" Айна , а кто это у нас тут насрал ?\"[RESPONSE_TOKEN]Услышав последнее слово , она в страхе припала к полу и стала заползать под машину , ожидая наказания .\n",
      "RELEVANCE: 0.9674630761146545\n",
      "\n",
      "INPUT_STRING: [CLS]Услышав последнее слово , она в страхе припала к полу и стала заползать под машину , ожидая наказания .[RESPONSE_TOKEN]Так я убедился , что она воспринимает именно само слово , а не жесты или интонацию голоса .\n",
      "RELEVANCE: 0.9766368269920349\n",
      "\n",
      "INPUT_STRING: [CLS]Так я убедился , что она воспринимает именно само слово , а не жесты или интонацию голоса .[RESPONSE_TOKEN]Потом я сам заводил собак и узнал , что это действительно так .\n",
      "RELEVANCE: 0.9627490043640137\n",
      "\n",
      "INPUT_STRING: [CLS]Потом я сам заводил собак и узнал , что это действительно так .[RESPONSE_TOKEN]Собаки запоминают слова и даже отличают очень похожие .\n",
      "RELEVANCE: 0.3337310552597046\n",
      "\n",
      "INPUT_STRING: [CLS]Собаки запоминают слова и даже отличают очень похожие .[RESPONSE_TOKEN]Последняя моя собака могла отличать , когда я обращаюсь к ней , а когда рассказываю кому – то про нее в контексте .\n",
      "RELEVANCE: 0.9604668617248535\n",
      "\n",
      "INPUT_STRING: [CLS]Последняя моя собака могла отличать , когда я обращаюсь к ней , а когда рассказываю кому – то про нее в контексте .[RESPONSE_TOKEN]То есть не реагировала на свое имя , если я просто говорю про нее , а не обращаюсь к ней .\n",
      "RELEVANCE: 0.970589816570282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialog = [item for item in original_dialog_1.split('\\n') if item]\n",
    "dialog_len = 1\n",
    "temp_dialog_len = 0\n",
    "for i in range(dialog_len, len(dialog) - dialog_len+1):\n",
    "    part = dialog[i - dialog_len:i + dialog_len]\n",
    "    context = part[:dialog_len]\n",
    "    response = part[-1]\n",
    "\n",
    "    relevance, input_string = relevance_ranker.rank(context, response)\n",
    "    print(F\"INPUT_STRING: {input_string}\")\n",
    "    print(f\"RELEVANCE: {relevance}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог. Эта модель не работает совсем"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение датасета"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### перевод в jay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = \"/home/dilyara.baymurzina/markov_dataset/preprocessed_ru_convers_tokenized.txt\"\n",
    "dialogues = []\n",
    "with open(original_path, 'r') as original_dataset:\n",
    "    prev_content = \"\"\n",
    "    dialog = []\n",
    "    for content in original_dataset:\n",
    "        if len(content) == 1:\n",
    "            dialog = \"@@@\".join(dialog)\n",
    "            dialogues.append(dialog)\n",
    "            dialog = []\n",
    "        else:\n",
    "            prev_content = content\n",
    "            dialog.append(content.strip())\n",
    "dt.Frame({\n",
    "\t\"dialogue\": dialogues,\n",
    "}\n",
    ").to_jay(\"./datasets/russian_chats/markov_dialogues.jay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dt.fread(\"./datasets/russian_chats/markov_dialogues.jay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>dialogue</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>А вообще уже было Здесь ещё точно не было !@@@Я по&#133;</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>Я думал в / kucha . d3 . ru / лулзы ловят , а полу&#133;</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>это чё за хоббит ?@@@а ... понял ... беззубый хобб&#133;</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>Это какой – то ... позор !( с ) Бывает .@@@Социали&#133;</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>Но зачем ?@@@Девчонки ведутся !@@@Логично .@@@Мне &#133;</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>это действительно не сложно , я за вечер научился &#133;</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>И как её гладить после стирки ?@@@вот – вот , деву&#133;</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>У него есть все шансы найти себе подругу .@@@Да , &#133;</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>Видимо индийцы с цыганами всё – таки родственники &#133;</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>Наконец пытается привлечь , потому как на конец не&#133;</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>Мне кажется или голос на видео синтетический ?@@@н&#133;</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>Наконец пытается привлечь , потому как на конец не&#133;</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>Но как ???@@@фотошоп же !</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>А я такое видел в репортаже с чемпионата по питью &#133;</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>никогда не понимал , почему проблемы дольщиков дол&#133;</td></tr>\n",
       "    <tr><td class='row_index'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td></tr>\n",
       "    <tr><td class='row_index'>2,643,588</td><td>Извини .@@@Мне было страшно .@@@Я болен .@@@Я схож&#133;</td></tr>\n",
       "    <tr><td class='row_index'>2,643,589</td><td>Интересно , он был бы столь же прытким , если бы з&#133;</td></tr>\n",
       "    <tr><td class='row_index'>2,643,590</td><td>Кто это ? Кто это ? Я не могу сказать .@@@на сайте&#133;</td></tr>\n",
       "    <tr><td class='row_index'>2,643,591</td><td></td></tr>\n",
       "    <tr><td class='row_index'>2,643,592</td><td></td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>2,643,593 rows &times; 1 column</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#7f2c89f36b70 2643593x1>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Проповедники приперлись в парк , где в жаркий день отдыхали люди , и получили эмоциональный ответ .',\n",
       " 'Автор бредит гомосЭксуалистами .',\n",
       " 'Почитайте описание видео , пожалуйста .',\n",
       " 'У меня свои глаза и уши .',\n",
       " 'Не надо искать заговор и фобию там , где её нет .',\n",
       " 'Ну вы же сами так подали свой пост .',\n",
       " 'И потом , какая разница какой секс – ориентации хулиган ?']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1002, 0].split(\"@@@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проповедники приперлись в парк , где в жаркий день отдыхали люди , и получили эмоциональный ответ .\n",
      "Автор бредит гомосЭксуалистами .\n",
      "Почитайте описание видео , пожалуйста .\n",
      "У меня свои глаза и уши .\n",
      "Не надо искать заговор и фобию там , где её нет .\n",
      "Ну вы же сами так подали свой пост .\n",
      "И потом , какая разница какой секс – ориентации хулиган ?\n",
      "CONTEXT: Проповедники приперлись в парк , где в жаркий день отдыхали люди , и получили эмоциональный ответ . RESPONSE: Автор бредит гомосЭксуалистами .\n",
      "CONTEXT: Проповедники приперлись в парк , где в жаркий день отдыхали люди , и получили эмоциональный ответ . [SEP] Автор бредит гомосЭксуалистами . [SEP] Почитайте описание видео , пожалуйста . RESPONSE: У меня свои глаза и уши .\n",
      "CONTEXT: Проповедники приперлись в парк , где в жаркий день отдыхали люди , и получили эмоциональный ответ . [SEP] Автор бредит гомосЭксуалистами . [SEP] Почитайте описание видео , пожалуйста . [SEP] У меня свои глаза и уши . [SEP] Не надо искать заговор и фобию там , где её нет . RESPONSE: Ну вы же сами так подали свой пост .\n"
     ]
    }
   ],
   "source": [
    "dialog_1 = dataset[1002, 0].split(\"@@@\")\n",
    "print(\"\\n\".join(dialog_1))\n",
    "aug_dialog_1 = []\n",
    "\n",
    "for i in range(1, len(dialog_1), 2):\n",
    "    context = dialog_1[:i]\n",
    "    context = \" [SEP] \".join(context)\n",
    "    response = dialog_1[i]\n",
    "    print(f\"CONTEXT: {context} RESPONSE: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "total 11G\n",
      "-rw-rw-r-- 1 kosenko kosenko  6.9G Dec 15 21:03 augumented_markov_dialogues.jay\n",
      "-rw-rw-r-- 1 kosenko kosenko  3.1G Dec 15 19:54 markov_dialogues.jay\n",
      "-rw-rw-r-- 1 kosenko kosenko 1016K Dec 15 19:29 part_markov.txt\n",
      "-rwxrwxrwx 1 kosenko kosenko  131M Dec 15 00:33 telegram_chats.zip\n",
      "-rw-rw-r-- 1 kosenko kosenko   168 Dec 15 19:44 test.jay\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./datasets/russian_chats/ -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert original dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = []\n",
    "\n",
    "dataset_len = dataset[:, dt.count()][0, 0]\n",
    "\n",
    "for pos in range(300_000):\n",
    "    dialog_sample = dataset[pos, 0].split(\"@@@\")\n",
    "\n",
    "    for i in range(1, len(dialog_sample), 2):\n",
    "        context = dialog_sample[:i]\n",
    "        context = \" [SEP] \".join(context)\n",
    "        response = dialog_sample[i]\n",
    "        \n",
    "        dialogues.append({\n",
    "            \"context\": context,\n",
    "            \"response\": response\n",
    "        })\n",
    "        \n",
    "\n",
    "\n",
    "dt.Frame(dialogues).to_jay(\"./datasets/russian_chats/augumented_markov_dialogues.jay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afbd04eaf482342bd8c806741887bf29b8900f429828e19eaba1f287fa9febed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
