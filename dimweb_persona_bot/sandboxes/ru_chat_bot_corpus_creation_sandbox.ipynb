{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cornell_movie_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/cornell_movie_corpus/cornell_movie_corpus.txt\"\n",
    "part_dataset = \"./datasets/cornell_movie_corpus/cornell_movie_corpus_part.txt\"\n",
    "dataset_size = 10000\n",
    "with open(dataset_path, 'r') as original_dataset:\n",
    "    with open(part_dataset, 'w') as temp_dataset:\n",
    "        part_dataset_str = \"\".join([next(original_dataset) for _ in range(dataset_size)])\n",
    "        temp_dataset.write(part_dataset_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: '2_Привет, норм а у тебя?' | Input data: ['1_Привет, как дела?']\n",
      "Label: '1_Сижу смотрю мемы вк' | Input data: ['1_Привет, как дела?', '2_Привет, норм а у тебя?']\n",
      "Label: '2_Видел новый мем с собакой-кусакой?' | Input data: ['1_Привет, как дела?', '2_Привет, норм а у тебя?', '1_Сижу смотрю мемы вк']\n",
      "Label: '1_Нет, покажи' | Input data: ['1_Привет, как дела?', '2_Привет, норм а у тебя?', '1_Сижу смотрю мемы вк', '2_Видел новый мем с собакой-кусакой?']\n",
      "Dialog: ['1_Привет, как дела?', '2_Привет, норм а у тебя?']\n",
      "Dialog: ['1_Привет, как дела?', '2_Привет, норм а у тебя?', '1_Сижу смотрю мемы вк', '2_Видел новый мем с собакой-кусакой?']\n",
      "---\n",
      "Dialog: ['2_Привет, норм а у тебя?', '1_Сижу смотрю мемы вк']\n",
      "Dialog: ['2_Привет, норм а у тебя?', '1_Сижу смотрю мемы вк', '2_Видел новый мем с собакой-кусакой?', '1_Нет, покажи']\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    " \"1_Привет, как дела?\",\n",
    " \"2_Привет, норм а у тебя?\",\n",
    " \"1_Сижу смотрю мемы вк\",\n",
    " \"2_Видел новый мем с собакой-кусакой?\",\n",
    " \"1_Нет, покажи\"\n",
    "]\n",
    "for i in range(1, len(test_data), 1):\n",
    "    input_data = test_data[:i]\n",
    "    labels = test_data[i]\n",
    "    print(f\"Label: '{labels}' | Input data: {input_data}\") \n",
    "    \n",
    "for i in range(1, len(test_data) // 2 + 1):\n",
    "    input_data = test_data[:i*2]\n",
    "    print(f\"Dialog: {input_data}\") \n",
    "print(\"---\")\n",
    "test_data_2 = test_data[:]\n",
    "test_data_2.pop(0)\n",
    "for i in range(1, len(test_data_2) // 2 +1):\n",
    "    input_data = test_data_2[:i*2]\n",
    "    print(f\"Dialog: {input_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Ты приглашаешь меня на свидание. Это так мило. Напомни, как тебя зовут?',\n",
       "  'Забудь об этом.'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '0_0_1',\n",
       " 'dataset_source': 'RUCornellMovieCorpusV1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_cornel_movie_corpus_dataloaders import RUCornellMovieCorpusV1\n",
    "    \n",
    "\n",
    "dataset = RUCornellMovieCorpusV1(\n",
    "    input_dataset_path='./datasets/cornell_movie_corpus/cornell_movie_corpus.txt'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Я был?', 'Ты никогда не хотела встречаться со мной, не так ли?'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '11_1_1',\n",
       " 'dataset_source': 'RUCornellMovieCorpusV1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Ты приглашаешь меня на свидание. Это так мило...</td>\n",
       "      <td></td>\n",
       "      <td>0_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Боже, если бы только мы могли найти Кэт парня...</td>\n",
       "      <td></td>\n",
       "      <td>1_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Как продвигается наш маленький план \"Найди де...</td>\n",
       "      <td></td>\n",
       "      <td>2_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Вот так., Куда?]</td>\n",
       "      <td></td>\n",
       "      <td>3_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[У тебя что-то на уме?, Я рассчитывал, что вы ...</td>\n",
       "      <td></td>\n",
       "      <td>4_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110425</th>\n",
       "      <td>[Это контрабанда. Не спрашивай. Но я хотел теб...</td>\n",
       "      <td></td>\n",
       "      <td>51101_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110426</th>\n",
       "      <td>[Ты уходишь от нас?, О нет. Мы всегда будем вм...</td>\n",
       "      <td></td>\n",
       "      <td>51102_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110427</th>\n",
       "      <td>[Совет кардиналов! Я так нервничаю! Что, если ...</td>\n",
       "      <td></td>\n",
       "      <td>51103_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110428</th>\n",
       "      <td>[Совет кардиналов! Я так нервничаю! Что, если ...</td>\n",
       "      <td></td>\n",
       "      <td>51103_0_2</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110429</th>\n",
       "      <td>[Прямо в ад. Шучу. Где этот автобус?, ]</td>\n",
       "      <td></td>\n",
       "      <td>51103_1_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110430 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context knowledge  \\\n",
       "0       [Ты приглашаешь меня на свидание. Это так мило...             \n",
       "1       [Боже, если бы только мы могли найти Кэт парня...             \n",
       "2       [Как продвигается наш маленький план \"Найди де...             \n",
       "3                                       [Вот так., Куда?]             \n",
       "4       [У тебя что-то на уме?, Я рассчитывал, что вы ...             \n",
       "...                                                   ...       ...   \n",
       "110425  [Это контрабанда. Не спрашивай. Но я хотел теб...             \n",
       "110426  [Ты уходишь от нас?, О нет. Мы всегда будем вм...             \n",
       "110427  [Совет кардиналов! Я так нервничаю! Что, если ...             \n",
       "110428  [Совет кардиналов! Я так нервничаю! Что, если ...             \n",
       "110429            [Прямо в ад. Шучу. Где этот автобус?, ]             \n",
       "\n",
       "        sample_id          dataset_source  \n",
       "0           0_0_1  RUCornellMovieCorpusV1  \n",
       "1           1_0_1  RUCornellMovieCorpusV1  \n",
       "2           2_0_1  RUCornellMovieCorpusV1  \n",
       "3           3_0_1  RUCornellMovieCorpusV1  \n",
       "4           4_0_1  RUCornellMovieCorpusV1  \n",
       "...           ...                     ...  \n",
       "110425  51101_0_1  RUCornellMovieCorpusV1  \n",
       "110426  51102_0_1  RUCornellMovieCorpusV1  \n",
       "110427  51103_0_1  RUCornellMovieCorpusV1  \n",
       "110428  51103_0_2  RUCornellMovieCorpusV1  \n",
       "110429  51103_1_1  RUCornellMovieCorpusV1  \n",
       "\n",
       "[110430 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ru anekdots dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Как водичка ?',\n",
       "  'А я здесь как женшина сижу, а не как термометр.'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '0_0_1',\n",
       " 'dataset_source': 'RUAnekdotsDialogsV1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_anekdots_dialogs_dataloaders import RUAnekdotsDialogsV1\n",
    "\n",
    "dataset = RUAnekdotsDialogsV1(\n",
    "    input_dataset_path='./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs.txt'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['В стране куча хорошеньких девушек, которые не хотят замуж.',\n",
       "  'Откуда знаешь?'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '40_0_1',\n",
       " 'dataset_source': 'RUAnekdotsDialogsV1'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Как водичка ?, А я здесь как женшина сижу, а ...</td>\n",
       "      <td></td>\n",
       "      <td>0_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Я затрудняюсь поставить вам диагноз ... Навер...</td>\n",
       "      <td></td>\n",
       "      <td>1_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Что такое дефицит в маркистском понимании?, Э...</td>\n",
       "      <td></td>\n",
       "      <td>2_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Что такое дефицит в маркистском понимании?, Э...</td>\n",
       "      <td></td>\n",
       "      <td>2_0_2</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Это объективная реальность, не данная нам в о...</td>\n",
       "      <td></td>\n",
       "      <td>2_1_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164769</th>\n",
       "      <td>[Алло, милиция?!, Да!, Быстрее приезжайте, мен...</td>\n",
       "      <td></td>\n",
       "      <td>87718_0_3</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164770</th>\n",
       "      <td>[Да!, Быстрее приезжайте, меня насилуют!]</td>\n",
       "      <td></td>\n",
       "      <td>87718_1_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164771</th>\n",
       "      <td>[Да!, Быстрее приезжайте, меня насилуют!, Куда...</td>\n",
       "      <td></td>\n",
       "      <td>87718_1_2</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164772</th>\n",
       "      <td>[Пап, я в пятницу на свадьбу иду, дай денег., ...</td>\n",
       "      <td></td>\n",
       "      <td>87719_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164773</th>\n",
       "      <td>[Пять тысяч хватит?, Ну ты чо?! Платье, фата...]</td>\n",
       "      <td></td>\n",
       "      <td>87719_1_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context knowledge  \\\n",
       "0       [Как водичка ?, А я здесь как женшина сижу, а ...             \n",
       "1       [Я затрудняюсь поставить вам диагноз ... Навер...             \n",
       "2       [Что такое дефицит в маркистском понимании?, Э...             \n",
       "3       [Что такое дефицит в маркистском понимании?, Э...             \n",
       "4       [Это объективная реальность, не данная нам в о...             \n",
       "...                                                   ...       ...   \n",
       "164769  [Алло, милиция?!, Да!, Быстрее приезжайте, мен...             \n",
       "164770          [Да!, Быстрее приезжайте, меня насилуют!]             \n",
       "164771  [Да!, Быстрее приезжайте, меня насилуют!, Куда...             \n",
       "164772  [Пап, я в пятницу на свадьбу иду, дай денег., ...             \n",
       "164773   [Пять тысяч хватит?, Ну ты чо?! Платье, фата...]             \n",
       "\n",
       "        sample_id       dataset_source  \n",
       "0           0_0_1  RUAnekdotsDialogsV1  \n",
       "1           1_0_1  RUAnekdotsDialogsV1  \n",
       "2           2_0_1  RUAnekdotsDialogsV1  \n",
       "3           2_0_2  RUAnekdotsDialogsV1  \n",
       "4           2_1_1  RUAnekdotsDialogsV1  \n",
       "...           ...                  ...  \n",
       "164769  87718_0_3  RUAnekdotsDialogsV1  \n",
       "164770  87718_1_1  RUAnekdotsDialogsV1  \n",
       "164771  87718_1_2  RUAnekdotsDialogsV1  \n",
       "164772  87719_0_1  RUAnekdotsDialogsV1  \n",
       "164773  87719_1_1  RUAnekdotsDialogsV1  \n",
       "\n",
       "[164774 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flibusta_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Почему тебя отпустили, а Кирилла нет?',\n",
       "  'Я сбежал, из горящей гостиницы.'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '0_0_1',\n",
       " 'dataset_source': 'RUFlibustaDialogsV1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_flibusta_dialogs_dataloaders import RUFlibustaDialogsV1\n",
    "\n",
    "dataset = RUFlibustaDialogsV1(\n",
    "    input_dataset_path='./datasets/flibusta_dialogues/flibusta_dialogues.txt'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Пряталась у себя в норе, чтобы зализать раны',\n",
       "  'Я всегда говорил, что в тебе есть что то от лисы'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '74_1_1',\n",
       " 'dataset_source': 'RUFlibustaDialogsV1'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Я буду курировать вашу работу от конструкторов.',\n",
       "  'Мужиков у нас там больше нет, что ли?'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '153_0_1',\n",
       " 'dataset_source': 'RUFlibustaDialogsV1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuBQ 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 0,\n",
       " 'ru_wiki_pageid': 58311,\n",
       " 'text': 'ЦСКА — советский и российский профессиональный хоккейный клуб из Москвы, выступающий в Континентальной хоккейной лиге. Основан в 1946 году под названием ЦДКА (Центральный дом Красной Армии). В 1951 году переименован в ЦДСА (Центральный дом Советской Армии), а в 1954 в ЦСК МО (Центральный спортивный клуб Министерства обороны), под которым выступал до 1959 года, и с тех пор носит название ЦСКА (Центральный Спортивный Клуб Армии).'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json\n",
    "import json\n",
    "data_dev = open('./datasets/ru_bq20/RuBQ_2.0_dev.json', 'r',) \n",
    "data_dev = json.load(data_dev)\n",
    "\n",
    "data_test = open('./datasets/ru_bq20/RuBQ_2.0_test.json', 'r')\n",
    "data_test = json.load(data_test)\n",
    "\n",
    "data_paragraphs = open('./datasets/ru_bq20/RuBQ_2.0_paragraphs.json', 'r')\n",
    "data_paragraphs = json.load(data_paragraphs)\n",
    "data_paragraphs = {item['uid']: item for item in data_paragraphs}\n",
    "# data_dev[0]\n",
    "data_paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'ru_wiki_pageid', 'text'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paragraphs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 4,\n",
       " 'question_text': 'Какой стране принадлежит знаменитый остров Пасхи?',\n",
       " 'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q14452 wdt:P17 ?answer\\n}',\n",
       " 'answer_text': 'Чили',\n",
       " 'question_uris': ['http://www.wikidata.org/entity/Q14452'],\n",
       " 'question_props': ['wdt:P17'],\n",
       " 'answers': [{'type': 'uri',\n",
       "   'label': 'Чили',\n",
       "   'value': 'http://www.wikidata.org/entity/Q298',\n",
       "   'wd_names': {'ru': ['Республика Чили', 'Чили'],\n",
       "    'en': ['Chile',\n",
       "     'República de Chile',\n",
       "     'Republic of Chile',\n",
       "     'cl',\n",
       "     'Republica de Chile',\n",
       "     'CHI',\n",
       "     '🇨🇱']},\n",
       "   'wp_names': ['Чилийская']}],\n",
       " 'paragraphs_uids': {'with_answer': [10785, 10782, 10783],\n",
       "  'all_related': [10782,\n",
       "   10783,\n",
       "   10784,\n",
       "   10785,\n",
       "   10786,\n",
       "   53027,\n",
       "   53028,\n",
       "   53029,\n",
       "   53030,\n",
       "   53031,\n",
       "   53032,\n",
       "   53033,\n",
       "   53034,\n",
       "   53035,\n",
       "   53036,\n",
       "   35776,\n",
       "   35777,\n",
       "   35778,\n",
       "   35779,\n",
       "   35780,\n",
       "   51707,\n",
       "   51708,\n",
       "   51709,\n",
       "   51710,\n",
       "   51711]},\n",
       " 'tags': ['1-hop'],\n",
       " 'RuBQ_version': '1.0',\n",
       " 'question_eng': 'Which country does the famous Easter island belong to?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 0,\n",
       " 'question_text': 'Что может вызвать цунами?',\n",
       " 'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q8070 wdt:P828 ?answer\\n}',\n",
       " 'answer_text': 'Землетрясение',\n",
       " 'question_uris': ['http://www.wikidata.org/entity/Q8070'],\n",
       " 'question_props': ['wdt:P828'],\n",
       " 'answers': [{'type': 'uri',\n",
       "   'label': 'землетрясение',\n",
       "   'value': 'http://www.wikidata.org/entity/Q7944',\n",
       "   'wd_names': {'ru': ['землетрясение', 'җир тетрәве'],\n",
       "    'en': ['seism',\n",
       "     'earthquake',\n",
       "     'seismic activity',\n",
       "     'fore shocks',\n",
       "     'tremor',\n",
       "     'earthquakes',\n",
       "     'earth quake',\n",
       "     'earthtemblor',\n",
       "     'foreshock',\n",
       "     'aftershock',\n",
       "     'quake',\n",
       "     'temblor',\n",
       "     'earth temblor',\n",
       "     'foreshocks',\n",
       "     'after shocks',\n",
       "     'earth quakes',\n",
       "     'after shock',\n",
       "     'earthtremor',\n",
       "     'convulsion',\n",
       "     'earth tremor',\n",
       "     'shock',\n",
       "     'fore shock',\n",
       "     'aftershocks']},\n",
       "   'wp_names': ['землетрясениям']},\n",
       "  {'type': 'uri',\n",
       "   'label': 'метеорит',\n",
       "   'value': 'http://www.wikidata.org/entity/Q60186',\n",
       "   'wd_names': {'ru': ['метеорит', 'Метеориты', 'Аэролиты'],\n",
       "    'en': ['shooting star', 'meteorite']},\n",
       "   'wp_names': []},\n",
       "  {'type': 'uri',\n",
       "   'label': 'оползень',\n",
       "   'value': 'http://www.wikidata.org/entity/Q167903',\n",
       "   'wd_names': {'ru': ['оползень', 'оползни'],\n",
       "    'en': ['Rock avalanche', 'landslide', 'landslip']},\n",
       "   'wp_names': ['оползни', 'оползнями']},\n",
       "  {'type': 'uri',\n",
       "   'label': 'Проект Seal',\n",
       "   'value': 'http://www.wikidata.org/entity/Q2580904',\n",
       "   'wd_names': {'ru': ['Проект Seal'], 'en': ['tsunami bomb']},\n",
       "   'wp_names': []},\n",
       "  {'type': 'uri',\n",
       "   'label': 'подводный оползень',\n",
       "   'value': 'http://www.wikidata.org/entity/Q5975740',\n",
       "   'wd_names': {'ru': [],\n",
       "    'en': ['undersea landslide',\n",
       "     'submarine landslide',\n",
       "     'underwater landslide']},\n",
       "   'wp_names': []},\n",
       "  {'type': 'uri',\n",
       "   'label': 'извержение вулкана',\n",
       "   'value': 'http://www.wikidata.org/entity/Q7692360',\n",
       "   'wd_names': {'ru': ['Фреатическое извержение',\n",
       "     'Вулканические извержения',\n",
       "     'Стромболианское извержение',\n",
       "     'извержение вулкана',\n",
       "     'Гавайское извержение',\n",
       "     'Газовое извержение',\n",
       "     'Вулканическое извержение',\n",
       "     'Пелейское извержение'],\n",
       "    'en': ['volcano eruption', 'volcanic eruption', 'eruption']},\n",
       "   'wp_names': ['извержения вулкана']}],\n",
       " 'paragraphs_uids': {'with_answer': [35622],\n",
       "  'all_related': [35622,\n",
       "   35623,\n",
       "   35624,\n",
       "   35625,\n",
       "   35626,\n",
       "   35632,\n",
       "   35633,\n",
       "   35634,\n",
       "   35635,\n",
       "   35636,\n",
       "   35637,\n",
       "   35638,\n",
       "   35639,\n",
       "   35640,\n",
       "   35641,\n",
       "   35642,\n",
       "   35643,\n",
       "   35644,\n",
       "   35645,\n",
       "   35646,\n",
       "   35647,\n",
       "   35648,\n",
       "   35649,\n",
       "   35650,\n",
       "   35651]},\n",
       " 'tags': ['1-hop'],\n",
       " 'RuBQ_version': '1.0',\n",
       " 'question_eng': 'What can cause a tsunami?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'question_text', 'query', 'answer_text', 'question_uris', 'question_props', 'answers', 'paragraphs_uids', 'tags', 'RuBQ_version', 'question_eng'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data_dev[10]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Как называлась столица Крымского ханства?',\n",
       " 'Бахчисарай',\n",
       " 'При образовании в Крыму независимого от Орды государства столица была перенесена в укреплённую горную крепость Кырк-Ер, затем в расположенный в долине у подножия Кырк-Ера Салачик и, наконец, в 1532 году во вновь построенный город Бахчисарай.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_paragraph_id = sample['paragraphs_uids']['with_answer'][0]\n",
    "info_paragraph = data_paragraphs[info_paragraph_id]['text']\n",
    "\n",
    "sample['question_text'], sample['answer_text'], info_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = {}\n",
    "alldata['questions'] = data_dev + data_test\n",
    "alldata['paragraphs'] = data_paragraphs\n",
    "\n",
    "# save json\n",
    "with open('./datasets/ru_bq20/RuBQ_2.0_all.json', 'w', encoding='utf-8') as outfile:\n",
    "\tjson.dump(alldata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 4,\n",
       " 'question_text': 'Какой стране принадлежит знаменитый остров Пасхи?',\n",
       " 'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q14452 wdt:P17 ?answer\\n}',\n",
       " 'answer_text': 'Чили',\n",
       " 'question_uris': ['http://www.wikidata.org/entity/Q14452'],\n",
       " 'question_props': ['wdt:P17'],\n",
       " 'answers': [{'type': 'uri',\n",
       "   'label': 'Чили',\n",
       "   'value': 'http://www.wikidata.org/entity/Q298',\n",
       "   'wd_names': {'ru': ['Республика Чили', 'Чили'],\n",
       "    'en': ['Chile',\n",
       "     'República de Chile',\n",
       "     'Republic of Chile',\n",
       "     'cl',\n",
       "     'Republica de Chile',\n",
       "     'CHI',\n",
       "     '🇨🇱']},\n",
       "   'wp_names': ['Чилийская']}],\n",
       " 'paragraphs_uids': {'with_answer': [10785, 10782, 10783],\n",
       "  'all_related': [10782,\n",
       "   10783,\n",
       "   10784,\n",
       "   10785,\n",
       "   10786,\n",
       "   53027,\n",
       "   53028,\n",
       "   53029,\n",
       "   53030,\n",
       "   53031,\n",
       "   53032,\n",
       "   53033,\n",
       "   53034,\n",
       "   53035,\n",
       "   53036,\n",
       "   35776,\n",
       "   35777,\n",
       "   35778,\n",
       "   35779,\n",
       "   35780,\n",
       "   51707,\n",
       "   51708,\n",
       "   51709,\n",
       "   51710,\n",
       "   51711]},\n",
       " 'tags': ['1-hop'],\n",
       " 'RuBQ_version': '1.0',\n",
       " 'question_eng': 'Which country does the famous Easter island belong to?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.dumps(alldata))['questions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['Какой стране принадлежит знаменитый остров Пасхи?'],\n",
       " 'knowledge': ['остров Пасхи (нидерл. Paasch-Eyland; исп. Isla de Pascua), названный так голландским мореплавателем Якобом Роггевеном, потому что он открыл его в день Пасхи 1722 года.Очень часто остров Пасхи называют Рапануи (в переводе — «Большой Рапа»). Такое название остров получил благодаря таитянским мореплавателям, использовавшим его, чтобы различать остров Пасхи и остров Рапа-Ити (в переводе — «Малый Рапа»), лежащий в 650 км к югу от Таити, и имеющий топологическое сходство с ним. В августе 2018 года власти страны, согласно Указу президента Чили, ускорили процесс рассмотрения законопроекта о переименовании Острова Пасхи в Рапа-Нуи.'],\n",
       " 'sample_id': '0',\n",
       " 'label': 'Чили',\n",
       " 'dataset_source': 'RURubq20V1'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_rubq20_dataloaders import RURubq20V1\n",
    "\n",
    "\n",
    "dataset = RURubq20V1(\n",
    "    input_dataset_path='./datasets/ru_bq20/RuBQ_2.0_all.json'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['При каком российском монархе возник Государственный Музей Эрмитаж?'],\n",
       " 'knowledge': ['Свою историю музей начинал с коллекции произведений искусства, приобретённых в частном порядке российской императрицей Екатериной II. Первоначально это собрание размещалось в специальном дворцовом флигеле — Эрмитаже (от фр. ermitage — место уединения, келья, приют отшельника, затворничество; ныне Малый Эрмитаж) — откуда и закрепилось общее название будущего музея. В 1852 году из сильно разросшейся коллекции был сформирован и открыт для посещения публичный музей, расположившийся в специально для этого построенном здании Нового Эрмитажа.'],\n",
       " 'sample_id': '100',\n",
       " 'label': 'Екатерина II',\n",
       " 'dataset_source': 'RURubq20V1'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd    \n",
    "\n",
    "train_path = \"./datasets/parus/train.jsonl\"\n",
    "valid_path = \"./datasets/parus/val.jsonl\"\n",
    "test_path = \"./datasets/parus/test.jsonl\"\n",
    "train_dataset = pd.read_json(train_path, lines=True)\n",
    "valid_dataset = pd.read_json(valid_path, lines=True)\n",
    "test_dataset = pd.read_json(test_path, lines=True)\n",
    "dataset = pd.concat([train_dataset, valid_dataset])\n",
    "dataset.to_csv(\"./datasets/parus/parus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>choice1</th>\n",
       "      <th>choice2</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Моё тело отбрасывает тень на траву.</td>\n",
       "      <td>Солнце уже поднялось.</td>\n",
       "      <td>Трава уже подстрижена.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Женщина снисходительно относилась к странному ...</td>\n",
       "      <td>Женщина знала, что её подруга переживает трудн...</td>\n",
       "      <td>Женщина чувствовала, что подруга пользуется её...</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Женщины встретились попить кофе.</td>\n",
       "      <td>Их кафе открылось в новом месте.</td>\n",
       "      <td>Им хотелось пересечься друг с другом.</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Бегунья была в шортах.</td>\n",
       "      <td>Прогноз обещал высокую температуру.</td>\n",
       "      <td>Она планировала бежать вдоль пляжа.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Гости вечеринки прятались за диваном.</td>\n",
       "      <td>Это была вечеринка-сюрприз.</td>\n",
       "      <td>Это был день рождения.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0                Моё тело отбрасывает тень на траву.   \n",
       "1  Женщина снисходительно относилась к странному ...   \n",
       "2                   Женщины встретились попить кофе.   \n",
       "3                             Бегунья была в шортах.   \n",
       "4              Гости вечеринки прятались за диваном.   \n",
       "\n",
       "                                             choice1  \\\n",
       "0                              Солнце уже поднялось.   \n",
       "1  Женщина знала, что её подруга переживает трудн...   \n",
       "2                   Их кафе открылось в новом месте.   \n",
       "3                Прогноз обещал высокую температуру.   \n",
       "4                        Это была вечеринка-сюрприз.   \n",
       "\n",
       "                                             choice2 question  label  idx  \n",
       "0                             Трава уже подстрижена.    cause      0    0  \n",
       "1  Женщина чувствовала, что подруга пользуется её...    cause      0    1  \n",
       "2              Им хотелось пересечься друг с другом.    cause      1    2  \n",
       "3                Она планировала бежать вдоль пляжа.    cause      0    3  \n",
       "4                             Это был день рождения.    cause      0    4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./datasets/parus/parus.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Моё тело отбрасывает тень на траву.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Солнце уже поднялось.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Женщина снисходительно относилась к странному...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Женщина знала, что её подруга переживает трудн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Женщины встретились попить кофе.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Им хотелось пересечься друг с другом.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Бегунья была в шортах.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Прогноз обещал высокую температуру.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Гости вечеринки прятались за диваном.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Это была вечеринка-сюрприз.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[В ушах звенело.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>95</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Я ходил на концерт.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[Я прибралась дома.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>96</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Я ждала друзей.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[Авиакомпания повредила мой багаж.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>97</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Они предложили мне компенсацию.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[Чинить компьютер было бы слишком дорого.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>98</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Я купил новый.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[Женщина была в плохом настроении.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>99</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>Она попросила подругу оставить её в покое.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context knowledge sample_id  \\\n",
       "0                [Моё тело отбрасывает тень на траву.]        []         0   \n",
       "1    [Женщина снисходительно относилась к странному...        []         1   \n",
       "2                   [Женщины встретились попить кофе.]        []         2   \n",
       "3                             [Бегунья была в шортах.]        []         3   \n",
       "4              [Гости вечеринки прятались за диваном.]        []         4   \n",
       "..                                                 ...       ...       ...   \n",
       "495                                  [В ушах звенело.]        []        95   \n",
       "496                               [Я прибралась дома.]        []        96   \n",
       "497                [Авиакомпания повредила мой багаж.]        []        97   \n",
       "498         [Чинить компьютер было бы слишком дорого.]        []        98   \n",
       "499                [Женщина была в плохом настроении.]        []        99   \n",
       "\n",
       "       dataset_source                                              label  \n",
       "0    RUParusDatasetV1                              Солнце уже поднялось.  \n",
       "1    RUParusDatasetV1  Женщина знала, что её подруга переживает трудн...  \n",
       "2    RUParusDatasetV1              Им хотелось пересечься друг с другом.  \n",
       "3    RUParusDatasetV1                Прогноз обещал высокую температуру.  \n",
       "4    RUParusDatasetV1                        Это была вечеринка-сюрприз.  \n",
       "..                ...                                                ...  \n",
       "495  RUParusDatasetV1                                Я ходил на концерт.  \n",
       "496  RUParusDatasetV1                                    Я ждала друзей.  \n",
       "497  RUParusDatasetV1                    Они предложили мне компенсацию.  \n",
       "498  RUParusDatasetV1                                     Я купил новый.  \n",
       "499  RUParusDatasetV1         Она попросила подругу оставить её в покое.  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_parus_dataloaders import RUParusDatasetV1\n",
    "dataset = RUParusDatasetV1(\n",
    "    input_dataset_path='./datasets/parus/parus.csv'\n",
    ")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# da_net_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"./datasets/da_net_qa/train.jsonl\"\n",
    "valid_path = \"./datasets/da_net_qa/val.jsonl\"\n",
    "\n",
    "train_dataset = pd.read_json(train_path, lines=True)\n",
    "valid_dataset = pd.read_json(valid_path, lines=True)\n",
    "dataset = pd.concat([train_dataset, valid_dataset], ignore_index=True)\n",
    "dataset.to_csv(\"./datasets/da_net_qa/da_net_qa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>«Вы́ставочный центр» — станция Московского мон...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Вднх - это выставочный центр?</td>\n",
       "      <td>Вы́ставка достиже́ний наро́дного хозя́йства  ,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Был ли джиган в black star?</td>\n",
       "      <td>Вместе с этим треком они выступили на церемони...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi конкурент apple?</td>\n",
       "      <td>Xiaomi — китайская компания, основанная в 2010...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Был ли автомат калашникова в вов?</td>\n",
       "      <td>Отметив некоторые недостатки и в целом удачную...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0      Вднх - это выставочный центр?   \n",
       "1      Вднх - это выставочный центр?   \n",
       "2        Был ли джиган в black star?   \n",
       "3            Xiaomi конкурент apple?   \n",
       "4  Был ли автомат калашникова в вов?   \n",
       "\n",
       "                                             passage  label  idx  \n",
       "0  «Вы́ставочный центр» — станция Московского мон...   True    0  \n",
       "1  Вы́ставка достиже́ний наро́дного хозя́йства  ,...   True    1  \n",
       "2  Вместе с этим треком они выступили на церемони...   True    2  \n",
       "3  Xiaomi — китайская компания, основанная в 2010...   True    3  \n",
       "4  Отметив некоторые недостатки и в целом удачную...  False    4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./datasets/da_net_qa/da_net_qa.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Вднх - это выставочный центр?]</td>\n",
       "      <td>[«Вы́ставочный центр» — станция Московского мо...</td>\n",
       "      <td>0</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Вднх - это выставочный центр?]</td>\n",
       "      <td>[Вы́ставка достиже́ний наро́дного хозя́йства  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Был ли джиган в black star?]</td>\n",
       "      <td>[Вместе с этим треком они выступили на церемон...</td>\n",
       "      <td>2</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Xiaomi конкурент apple?]</td>\n",
       "      <td>[Xiaomi — китайская компания, основанная в 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Был ли автомат калашникова в вов?]</td>\n",
       "      <td>[Отметив некоторые недостатки и в целом удачну...</td>\n",
       "      <td>4</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>[Живет ли впч в крови?]</td>\n",
       "      <td>[ДНК вируса многократно дублирует его белки, т...</td>\n",
       "      <td>2565</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>[Вредна ли фотоэпиляция в домашних условиях?]</td>\n",
       "      <td>[Проявляются в виде дерматитов различных форм,...</td>\n",
       "      <td>2566</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>[Были ли бездетными мария и иосиф?]</td>\n",
       "      <td>[О жизни его, кроме обстоятельств рождения Хри...</td>\n",
       "      <td>2567</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>[Есть ли у луны ядро?]</td>\n",
       "      <td>[Это движение является прецессионным; поворот ...</td>\n",
       "      <td>2568</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>[Был ли в ссср налог на бездетность?]</td>\n",
       "      <td>[Налог на бездетность существовал в СССР как «...</td>\n",
       "      <td>2569</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>Да</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context  \\\n",
       "0                   [Вднх - это выставочный центр?]   \n",
       "1                   [Вднх - это выставочный центр?]   \n",
       "2                     [Был ли джиган в black star?]   \n",
       "3                         [Xiaomi конкурент apple?]   \n",
       "4               [Был ли автомат калашникова в вов?]   \n",
       "...                                             ...   \n",
       "2565                        [Живет ли впч в крови?]   \n",
       "2566  [Вредна ли фотоэпиляция в домашних условиях?]   \n",
       "2567            [Были ли бездетными мария и иосиф?]   \n",
       "2568                         [Есть ли у луны ядро?]   \n",
       "2569          [Был ли в ссср налог на бездетность?]   \n",
       "\n",
       "                                              knowledge sample_id  \\\n",
       "0     [«Вы́ставочный центр» — станция Московского мо...         0   \n",
       "1     [Вы́ставка достиже́ний наро́дного хозя́йства  ...         1   \n",
       "2     [Вместе с этим треком они выступили на церемон...         2   \n",
       "3     [Xiaomi — китайская компания, основанная в 201...         3   \n",
       "4     [Отметив некоторые недостатки и в целом удачну...         4   \n",
       "...                                                 ...       ...   \n",
       "2565  [ДНК вируса многократно дублирует его белки, т...      2565   \n",
       "2566  [Проявляются в виде дерматитов различных форм,...      2566   \n",
       "2567  [О жизни его, кроме обстоятельств рождения Хри...      2567   \n",
       "2568  [Это движение является прецессионным; поворот ...      2568   \n",
       "2569  [Налог на бездетность существовал в СССР как «...      2569   \n",
       "\n",
       "          dataset_source label  \n",
       "0     RUDanetqaDatasetV1    Да  \n",
       "1     RUDanetqaDatasetV1    Да  \n",
       "2     RUDanetqaDatasetV1    Да  \n",
       "3     RUDanetqaDatasetV1    Да  \n",
       "4     RUDanetqaDatasetV1   Нет  \n",
       "...                  ...   ...  \n",
       "2565  RUDanetqaDatasetV1   Нет  \n",
       "2566  RUDanetqaDatasetV1    Да  \n",
       "2567  RUDanetqaDatasetV1   Нет  \n",
       "2568  RUDanetqaDatasetV1    Да  \n",
       "2569  RUDanetqaDatasetV1    Да  \n",
       "\n",
       "[2570 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_danetqa_dataloaders import RUDanetqaDatasetV1\n",
    "\n",
    "dataset = RUDanetqaDatasetV1(\n",
    "\tinput_dataset_path='./datasets/da_net_qa/da_net_qa.csv'\n",
    ")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ru persona chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "      <th>history</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[У меня любимая работа., Я уважаю людей., У ме...</td>\n",
       "      <td>[Привет) расскажи о себе., Привет) под вкусный...</td>\n",
       "      <td>0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[У меня любимая работа., Я уважаю людей., У ме...</td>\n",
       "      <td>[Привет) расскажи о себе., Привет) под вкусный...</td>\n",
       "      <td>0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Я бизнесмен., У меня скоро свадьба., Меня люб...</td>\n",
       "      <td>[Привет!, Привет,Как жизнь?]</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Я бизнесмен., У меня скоро свадьба., Меня люб...</td>\n",
       "      <td>[Привет!, Привет,Как жизнь?, Отлично) Солнышко...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Я пою в караоке., У меня есть супруга., Хорош...</td>\n",
       "      <td>[Привет. Как дела ?, Добрый день! Хорошо,  чем...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67013</th>\n",
       "      <td>[Я воспитатель., люблю готовить., люблю велосп...</td>\n",
       "      <td>[Приветик), Привет. Меня зовут Мария), Как дел...</td>\n",
       "      <td>10011_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67014</th>\n",
       "      <td>[Я воспитатель., люблю готовить., люблю велосп...</td>\n",
       "      <td>[Приветик), Привет. Меня зовут Мария), Как дел...</td>\n",
       "      <td>10011_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67015</th>\n",
       "      <td>[Я женат., Люблю свою жену., Работаю прорабом ...</td>\n",
       "      <td>[Привет! рада новому знакомству, как твои дела...</td>\n",
       "      <td>10012_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67016</th>\n",
       "      <td>[Я женат., Люблю свою жену., Работаю прорабом ...</td>\n",
       "      <td>[Привет! рада новому знакомству, как твои дела...</td>\n",
       "      <td>10012_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67017</th>\n",
       "      <td>[Я женат., Люблю свою жену., Работаю прорабом ...</td>\n",
       "      <td>[Привет! рада новому знакомству, как твои дела...</td>\n",
       "      <td>10012_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67018 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 persona  \\\n",
       "0      [У меня любимая работа., Я уважаю людей., У ме...   \n",
       "1      [У меня любимая работа., Я уважаю людей., У ме...   \n",
       "2      [Я бизнесмен., У меня скоро свадьба., Меня люб...   \n",
       "3      [Я бизнесмен., У меня скоро свадьба., Меня люб...   \n",
       "4      [Я пою в караоке., У меня есть супруга., Хорош...   \n",
       "...                                                  ...   \n",
       "67013  [Я воспитатель., люблю готовить., люблю велосп...   \n",
       "67014  [Я воспитатель., люблю готовить., люблю велосп...   \n",
       "67015  [Я женат., Люблю свою жену., Работаю прорабом ...   \n",
       "67016  [Я женат., Люблю свою жену., Работаю прорабом ...   \n",
       "67017  [Я женат., Люблю свою жену., Работаю прорабом ...   \n",
       "\n",
       "                                                 history sample_id  \n",
       "0      [Привет) расскажи о себе., Привет) под вкусный...       0_1  \n",
       "1      [Привет) расскажи о себе., Привет) под вкусный...       0_2  \n",
       "2                           [Привет!, Привет,Как жизнь?]       1_1  \n",
       "3      [Привет!, Привет,Как жизнь?, Отлично) Солнышко...       1_2  \n",
       "4      [Привет. Как дела ?, Добрый день! Хорошо,  чем...       2_1  \n",
       "...                                                  ...       ...  \n",
       "67013  [Приветик), Привет. Меня зовут Мария), Как дел...   10011_4  \n",
       "67014  [Приветик), Привет. Меня зовут Мария), Как дел...   10011_5  \n",
       "67015  [Привет! рада новому знакомству, как твои дела...   10012_1  \n",
       "67016  [Привет! рада новому знакомству, как твои дела...   10012_2  \n",
       "67017  [Привет! рада новому знакомству, как твои дела...   10012_3  \n",
       "\n",
       "[67018 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_persona_chat_dataloaders import RUPersonaChatDatasetV3\n",
    "\n",
    "dataset = RUPersonaChatDatasetV3(\n",
    "\tinput_dataset_path='./datasets/ru_persona_chat/dialogues.tsv'\n",
    ")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 2022\n",
    "# [cornell_movie_corpus]\n",
    "# [ru_persona_chat]\n",
    "# [ru_anekdots_dialogs]\n",
    "# [ru_flibusta_dialogues]\n",
    "# [ru_rubq20]\n",
    "# [ru_danetqa]\n",
    "# [ru_parus]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cornell_movie_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50592, 512)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1 = \"./datasets/cornell_movie_corpus/cornell_movie_corpus.txt\"\n",
    "dataset = open(data_path_1, \"r\", encoding=\"utf-8\").read().split(\"\\n\\n\\n\\n\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "\n",
    "open(\"./datasets/cornell_movie_corpus/cornell_movie_corpus_train.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(train))\n",
    "open(\"./datasets/cornell_movie_corpus/cornell_movie_corpus_test.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(test))\n",
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_persona_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9912, 101)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/ru_persona_chat/dialogues.tsv\", sep=\"\\t\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "train.to_csv(\"./datasets/ru_persona_chat/ru_persona_chat_train.tsv\", sep=\"\\t\", index=False)\n",
    "test.to_csv(\"./datasets/ru_persona_chat/ru_persona_chat_test.tsv\", sep=\"\\t\", index=False)\n",
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_anekdots_dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86843, 878)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1 = \"./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs.txt\"\n",
    "dataset = open(data_path_1, \"r\", encoding=\"utf-8\").read().split(\"\\n\\n\\n\\n\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "open(\"./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_train.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(train))\n",
    "open(\"./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_test.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(test))\n",
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_flibusta_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3268703, 33018)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1 = \"./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues.txt\"\n",
    "dataset = open(data_path_1, \"r\", encoding=\"utf-8\").read().split(\"\\n\\n\\n\\n\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "open(\"./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_train.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(train))\n",
    "open(\"./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_test.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(test))\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_rubq20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 30, 56952)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_dev = open('./datasets/ru_rubq20/RuBQ_2.0_dev.json', 'r',) \n",
    "data_dev = json.load(data_dev)\n",
    "\n",
    "data_test = open('./datasets/ru_rubq20/RuBQ_2.0_test.json', 'r')\n",
    "data_test = json.load(data_test)\n",
    "\n",
    "data_paragraphs = open('./datasets/ru_rubq20/RuBQ_2.0_paragraphs.json', 'r')\n",
    "data_paragraphs = json.load(data_paragraphs)\n",
    "data_paragraphs = {item['uid']: item for item in data_paragraphs}\n",
    "\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "all_questions = data_dev + data_test\n",
    "train_questions, test_questions = train_test_split(all_questions, test_size=0.01, random_state=RANDOM_SEED)\n",
    "\n",
    "train_data['questions'] = train_questions\n",
    "train_data['paragraphs'] = data_paragraphs\n",
    "test_data['paragraphs'] = data_paragraphs\n",
    "test_data['questions'] = test_questions\n",
    "\n",
    "with open('./datasets/ru_rubq20/ru_rubq20_train.json', 'w', encoding='utf-8') as outfile:\n",
    "\tjson.dump(train_data, outfile)\n",
    " \n",
    "with open('./datasets/ru_rubq20/ru_rubq20_test.json', 'w', encoding='utf-8') as outfile:\n",
    "\tjson.dump(test_data, outfile)\n",
    "\n",
    "len(train_questions), len(test_questions), len(data_paragraphs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_danetqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/ru_danetqa/ru_danetqa.csv\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "train.to_csv(\"./datasets/ru_danetqa/ru_danetqa_train.csv\", index=False)\n",
    "test.to_csv(\"./datasets/ru_danetqa/ru_danetqa_test.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/ru_parus/ru_parus.csv\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "train.to_csv(\"./datasets/ru_parus/ru_parus_train.csv\", index=False)\n",
    "test.to_csv(\"./datasets/ru_parus/ru_parus_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ru_persona_chat]\n",
    "# [cornell_movie_corpus]\n",
    "# [ru_anekdots_dialogs]\n",
    "# [flibusta_dialogues]\n",
    "# [RuBQ_2.0]\n",
    "# [da_net_qa]\n",
    "# [parus]\n",
    "\n",
    "from dimweb_persona_bot.dataloaders.ru_persona_chat_dataloaders import RUPersonaChatDatasetV3\n",
    "from dimweb_persona_bot.dataloaders.ru_cornel_movie_corpus_dataloaders import RUCornellMovieCorpusDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_anekdots_dialogs_dataloaders import RUAnekdotsDialogsDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_flibusta_dialogs_dataloaders import RUFlibustaDialogsDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_rubq20_dataloaders import RURubq20DatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_danetqa_dataloaders import RUDanetqaDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_parus_dataloaders import RUParusDatasetV1\n",
    "\n",
    "dataset_paths = [\n",
    "    {\n",
    "        \"data_path\": \"ru_persona_chat\",\n",
    "        \"dataset_class\": RUPersonaChatDatasetV3,\n",
    "        # tsv\n",
    "          \"extension\": \"tsv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_cornell_movie_corpus\",\n",
    "        \"dataset_class\": RUCornellMovieCorpusDatasetV1,\n",
    "        # txt\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_anekdots_dialogs\",\n",
    "        \"dataset_class\": RUAnekdotsDialogsDatasetV1,\n",
    "        # txt\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_flibusta_dialogues\",\n",
    "        \"dataset_class\": RUFlibustaDialogsDatasetV1,\n",
    "        # txt\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_rubq20\",\n",
    "        \"dataset_class\": RURubq20DatasetV1,\n",
    "        # json\n",
    "        \"extension\": \"json\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_danetqa\",\n",
    "        \"dataset_class\": RUDanetqaDatasetV1,\n",
    "        # csv\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_parus\",\n",
    "        \"dataset_class\": RUParusDatasetV1,\n",
    "        # csv\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_persona_chat/ru_persona_chat_train.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912/9912 [00:27<00:00, 366.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_persona_chat/ru_persona_chat_test.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:00<00:00, 387.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_cornell_movie_corpus/ru_cornell_movie_corpus_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50592it [00:00, 97198.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_cornell_movie_corpus/ru_cornell_movie_corpus_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [00:00, 139474.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "86843it [00:00, 110921.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:00, 148103.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3268703it [00:23, 137478.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33018it [00:00, 177105.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_rubq20/ru_rubq20_train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2880it [00:00, 47474.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_rubq20/ru_rubq20_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:00, 109416.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_danetqa/ru_danetqa_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2544/2544 [00:00<00:00, 11206.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_danetqa/ru_danetqa_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 10355.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_parus/ru_parus_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [00:00<00:00, 9644.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_parus/ru_parus_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 6846.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# 1 min 30 sec\n",
    "for dataset_path in dataset_paths:\n",
    "    extension = dataset_path['extension']\n",
    "    for status in ['train', 'test']:\n",
    "        path = dataset_path['data_path']\n",
    "        full_path = f\"./datasets/{path}/{path}_{status}.{extension}\"\n",
    "        seq2seq_path_csv = f\"./datasets/{path}/seq2seq_{status}.csv\"\n",
    "        seq2seq_path_parquet = f\"./datasets/{path}/seq2seq_{status}.parquet\"\n",
    "        print(full_path)\n",
    "        dataset = dataset_path['dataset_class'](\n",
    "            input_dataset_path=full_path\n",
    "        )\n",
    "        dataset = dataset.to_pandas()\n",
    "        dataset.to_csv(seq2seq_path_csv, index=False)\n",
    "        dataset.to_parquet(seq2seq_path_parquet, index=False)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# for dataset_path in dataset_paths:\n",
    "#     extension = dataset_path['extension']\n",
    "#     for status in ['train', 'test']:\n",
    "#         path = dataset_path['data_path']\n",
    "#         seq2seq_path_csv = f\"./datasets/{path}/seq2seq_{status}.csv\"\n",
    "#         seq2seq_path_parquet = f\"./datasets/{path}/seq2seq_{status}.parquet\"\n",
    "        \n",
    "#         dataset = pd.read_csv(seq2seq_path_csv)\n",
    "#         dataset.to_parquet(seq2seq_path_parquet, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# huggigface datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/ru_persona_chat/seq2seq_test.parquet',\n",
       " './datasets/ru_cornell_movie_corpus/seq2seq_test.parquet',\n",
       " './datasets/ru_anekdots_dialogs/seq2seq_test.parquet',\n",
       " './datasets/ru_flibusta_dialogues/seq2seq_test.parquet',\n",
       " './datasets/ru_rubq20/seq2seq_test.parquet',\n",
       " './datasets/ru_danetqa/seq2seq_test.parquet',\n",
       " './datasets/ru_parus/seq2seq_test.parquet']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paths = [\n",
    "    {\n",
    "        \"data_path\": \"ru_persona_chat\",\n",
    "        \"extension\": \"tsv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_cornell_movie_corpus\",\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_anekdots_dialogs\",\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_flibusta_dialogues\",\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_rubq20\",\n",
    "        \"extension\": \"json\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_danetqa\",\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_parus\",\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "]\n",
    "\n",
    "train_parquet_paths = []\n",
    "test_parquet_paths = []\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "    extension = dataset_path['extension']\n",
    "    for status in ['train', 'test']:\n",
    "        path = dataset_path['data_path']\n",
    "        seq2seq_path_parquet = f\"./datasets/{path}/seq2seq_{status}.parquet\"\n",
    "        if status == 'train':\n",
    "            train_parquet_paths.append(seq2seq_path_parquet)\n",
    "        else:\n",
    "            test_parquet_paths.append(seq2seq_path_parquet)\n",
    "test_parquet_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-fe2f19362784e9e0\n",
      "Reusing dataset parquet (/home/kosenko/.cache/huggingface/datasets/parquet/default-fe2f19362784e9e0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e93dd0d6f9842f3b2bd753bd89a035e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    \"parquet\", \n",
    "    data_files={\n",
    "        'train': train_parquet_paths, \n",
    "        'test': test_parquet_paths\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 10809.84 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Process.memory_info is expressed in bytes, so convert to megabytes\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'knowledge', 'dataset_source', 'label', 'sample_id'],\n",
       "        num_rows: 5100110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'knowledge', 'dataset_source', 'label', 'sample_id'],\n",
       "        num_rows: 51225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '<c> Привет привет ! Как настроение ? Чем занимаешься ?',\n",
       " 'knowledge': ' <k> Я фотограф. <s> У меня есть собака. <s> Мне нравится фотографировать. <s> Я люблю шоколад. <s> Я слушаю поп-рок.',\n",
       " 'dataset_source': 'RUPersonaChatDatasetV3',\n",
       " 'label': 'Привет! Я фотограф. А ты?',\n",
       " 'sample_id': 'RUPersonaChatDatasetV3_0_1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./models/google-t5-efficient-tiny-nl8-ru\")\n",
    "\n",
    "def text_lens(example):\n",
    "    context = tokenizer.batch_encode_plus(example['context'])\n",
    "    context = [len(item) for item in context['input_ids']]\n",
    "    \n",
    "    knowledge = tokenizer.batch_encode_plus(example['knowledge'])\n",
    "    knowledge = [len(item) for item in knowledge['input_ids']]\n",
    "    \n",
    "    labels = tokenizer.batch_encode_plus(example['label'])\n",
    "    labels = [len(item) for item in labels['input_ids']]\n",
    "    \n",
    "    return {\n",
    "        \"context_len\": context,\n",
    "        \"knowledge_len\": knowledge,\n",
    "        \"label_len\": labels\n",
    "    }\n",
    "\n",
    "def process_dataset(example):\n",
    "    context = tokenizer(\n",
    "        example['context'],\n",
    "        truncation=True,\n",
    "        max_length=479,\n",
    "    )\n",
    "    knowledge = tokenizer(\n",
    "        example['knowledge'],\n",
    "        truncation=True,\n",
    "        max_length=522,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        example['label'],\n",
    "        truncation=True,\n",
    "        max_length=333,\n",
    "        padding='longest'\n",
    "    )\n",
    "    \n",
    "    input_ids = []\n",
    "    next_prefix = tokenizer.encode(' => ')\n",
    "    \n",
    "    for con_ids, con_attn, know_ids, know_attn in zip(\n",
    "        context['input_ids'], \n",
    "        context['attention_mask'], \n",
    "        knowledge['input_ids'], \n",
    "        knowledge['attention_mask']):\n",
    "        new_input_ids = con_ids + know_ids + next_prefix\n",
    "        \n",
    "        input_ids.append(new_input_ids)\n",
    "    \n",
    "    input_ids = tokenizer.batch_decode(input_ids)\n",
    "    input_ids = tokenizer(\n",
    "        input_ids,\n",
    "        truncation=True,\n",
    "        padding='longest'\n",
    "    )\n",
    "    labels = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "        \n",
    "    return {\n",
    "        \"input_ids\": input_ids['input_ids'],\n",
    "        \"attention_mask\": input_ids['attention_mask'],\n",
    "        \"labels\": labels\n",
    "    }\n",
    "def process_dataset_t5(example):\n",
    "    context = tokenizer(\n",
    "        example['context'],\n",
    "        truncation=True,\n",
    "        max_length=233,\n",
    "    )\n",
    "    knowledge = tokenizer(\n",
    "        example['knowledge'],\n",
    "        truncation=True,\n",
    "        max_length=259,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        example['label'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='longest'\n",
    "    )\n",
    "    \n",
    "    input_ids = []\n",
    "    next_prefix = tokenizer.encode(' => ')\n",
    "    \n",
    "    for con_ids, con_attn, know_ids, know_attn in zip(\n",
    "        context['input_ids'], \n",
    "        context['attention_mask'], \n",
    "        knowledge['input_ids'], \n",
    "        knowledge['attention_mask']):\n",
    "        new_input_ids = con_ids + know_ids + next_prefix\n",
    "        \n",
    "        input_ids.append(new_input_ids)\n",
    "    \n",
    "    input_ids = tokenizer.batch_decode(input_ids)\n",
    "    input_ids = tokenizer(\n",
    "        input_ids,\n",
    "        truncation=True,\n",
    "        padding='longest',\n",
    "        max_length=512\n",
    "    )\n",
    "    labels = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "        \n",
    "    return {\n",
    "        \"input_ids\": input_ids['input_ids'],\n",
    "        \"attention_mask\": input_ids['attention_mask'],\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[3, 2, 14709, 6609, 15042, 6, 3, 12095, 6652, 3, 19473, 17148, 58, 1], [3, 2, 14709, 6609, 15042, 6, 3, 12095, 6652, 3, 19473, 17148, 58, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\n",
    "\t\"Привет, как дела?\",\n",
    "\t\"Привет, как дела?\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2865e32b7745ef8b57f7e6bfab5ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c328ba374b467aaf74fbb1a42aa0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb1665224ac470d86cc65e1de7335ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b380cf831edb45b2a084ac8c2a0d2703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564dc18b1b0e413d97cc9778d73f55a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ea97d244104c80ad4c2de54df5be42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43c4a891d5044ebbb1b837b4378c9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d040f80af9804ea0827645e259c1152e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d471fa6f9545b3a5053057a6ab06c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f8fa9270b447c798d0b3698e20555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf048f786c145be92be557c0c8077ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7aa101507504d338768bd93928d8488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be61f416d18c417ea7df9741ca826ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034c1d8ab3d5485b826eb5b2e8beee32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524b1d8264674302b3c5ac7fc91d8f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27efedcf1a3b4780b84fdf0ef29e39b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fa22ed8e6048dbababab6532c6069f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291d73df1c014c3c8112cc28ca24d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515144bb962e43f0b751e4ad61d801f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4dd69b62fd43748611c35dbd995d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf60bee09ef74cec84cfd9f04ee29140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f80f31834ae4dd4af4be4deefffa3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b738fffc5446f5bb9913455de5e2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14fb3fc4ea544369d1652d111edfdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9fb773a3cf4129bbc649b92cdd84ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb79041410804e54a417444d9ba458b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d44b0f730146de963abc4e8b703991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefcef96aa434335a54fc7c7b894caca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d697b8ea1066476bb282933cc1ee9217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6873361b2f44d39a12b96e381c27610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7638a62594c5490abd7dc2b6d72ace6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23e64bb854c4e3d8f92bf161832dcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset = dataset.map(\n",
    "#     process_dataset, \n",
    "#     batched=True,\n",
    "#     num_proc=16,   \n",
    "# )\n",
    "dataset = dataset.map(\n",
    "    process_dataset_t5, \n",
    "    batched=True,\n",
    "    num_proc=16,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map(\n",
    "#     text_lens,\n",
    "#     batched=True,\n",
    "#     num_proc=16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(\"./datasets/ru_dialog_dataset_v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "context_len = np.percentile(np.array(dataset['train']['context_len']), 99.95)\n",
    "context_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_len = np.percentile(np.array(dataset['train']['knowledge_len']), 99.99)\n",
    "knowledge_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_len+knowledge_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array(dataset['train']['label_len']), 99.999)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train t5 russian tosenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"./datasets/ru_dialog_dataset_v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'knowledge', 'dataset_source', 'label', 'sample_id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5100110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'knowledge', 'dataset_source', 'label', 'sample_id', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 51225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_text(example):\n",
    "    context = example['context']\n",
    "    knowledge = example['knowledge']\n",
    "    label = example['label']\n",
    "    full_text = []\n",
    "    for item_0, item_1, item_2 in zip(context, knowledge, label):\n",
    "        full_text.append(item_0 + item_1 + ' => '+ item_2)\n",
    "    \n",
    "    return {\n",
    "        \"full_text\": full_text   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    create_full_text,\n",
    "\tbatched=True,\n",
    "\tnum_proc=16,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<c> Привет привет ! Как настроение ? Чем занимаешься ? <k> Я фотограф. <s> У меня есть собака. <s> Мне нравится фотографировать. <s> Я люблю шоколад. <s> Я слушаю поп-рок. => Привет! Я фотограф. А ты?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        dataset[\"train\"][i : i + 1000][\"full_text\"]\n",
    "        for i in range(0, len(dataset[\"train\"]), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"google/t5-efficient-tiny-nl8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>c> <unk>ривет <unk>ривет! <unk>ак настроение? <unk>ем <unk>анимае<unk>с<unk>? <unk>k> <unk> <unk>ото<unk>ра<unk>. <unk>s> <unk> мен<unk> ест<unk> со<unk>ака. <unk>s> <unk>не нравитс<unk> <unk>ото<unk>ра<unk>ироват<unk>. <unk>s> <unk> л<unk>л<unk> <unk>околад. <unk>s> <unk> слу<unk>а<unk> <unk>о<unk>-рок. => <unk>ривет! <unk> <unk>ото<unk>ра<unk>. <unk> т<unk>?</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer.decode(\n",
    "    old_tokenizer.encode(dataset['train'][0]['full_text'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, len(old_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<c> Привет привет! Как настроение? Чем занимаешься? <k> Я фотограф. <s> У меня есть собака. <s> Мне нравится фотографировать. <s> Я люблю шоколад. <s> Я слушаю поп-рок. => Привет! Я фотограф. А ты?</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    tokenizer.encode(dataset['train'][0]['full_text'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/google-t5-efficient-tiny-nl8-ru/tokenizer_config.json',\n",
       " './models/google-t5-efficient-tiny-nl8-ru/special_tokens_map.json',\n",
       " './models/google-t5-efficient-tiny-nl8-ru/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./models/google-t5-efficient-tiny-nl8-ru\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afbd04eaf482342bd8c806741887bf29b8900f429828e19eaba1f287fa9febed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
