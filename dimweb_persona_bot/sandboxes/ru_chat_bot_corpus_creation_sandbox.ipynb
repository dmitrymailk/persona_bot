{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cornell_movie_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/cornell_movie_corpus/cornell_movie_corpus.txt\"\n",
    "part_dataset = \"./datasets/cornell_movie_corpus/cornell_movie_corpus_part.txt\"\n",
    "dataset_size = 10000\n",
    "with open(dataset_path, 'r') as original_dataset:\n",
    "    with open(part_dataset, 'w') as temp_dataset:\n",
    "        part_dataset_str = \"\".join([next(original_dataset) for _ in range(dataset_size)])\n",
    "        temp_dataset.write(part_dataset_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: '2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?' | Input data: ['1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?']\n",
      "Label: '1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫' | Input data: ['1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?', '2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?']\n",
      "Label: '2_–í–∏–¥–µ–ª –Ω–æ–≤—ã–π –º–µ–º —Å —Å–æ–±–∞–∫–æ–π-–∫—É—Å–∞–∫–æ–π?' | Input data: ['1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?', '2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?', '1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫']\n",
      "Label: '1_–ù–µ—Ç, –ø–æ–∫–∞–∂–∏' | Input data: ['1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?', '2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?', '1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫', '2_–í–∏–¥–µ–ª –Ω–æ–≤—ã–π –º–µ–º —Å —Å–æ–±–∞–∫–æ–π-–∫—É—Å–∞–∫–æ–π?']\n",
      "Dialog: ['1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?', '2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?']\n",
      "Dialog: ['1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?', '2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?', '1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫', '2_–í–∏–¥–µ–ª –Ω–æ–≤—ã–π –º–µ–º —Å —Å–æ–±–∞–∫–æ–π-–∫—É—Å–∞–∫–æ–π?']\n",
      "---\n",
      "Dialog: ['2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?', '1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫']\n",
      "Dialog: ['2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?', '1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫', '2_–í–∏–¥–µ–ª –Ω–æ–≤—ã–π –º–µ–º —Å —Å–æ–±–∞–∫–æ–π-–∫—É—Å–∞–∫–æ–π?', '1_–ù–µ—Ç, –ø–æ–∫–∞–∂–∏']\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    " \"1_–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\",\n",
    " \"2_–ü—Ä–∏–≤–µ—Ç, –Ω–æ—Ä–º –∞ —É —Ç–µ–±—è?\",\n",
    " \"1_–°–∏–∂—É —Å–º–æ—Ç—Ä—é –º–µ–º—ã –≤–∫\",\n",
    " \"2_–í–∏–¥–µ–ª –Ω–æ–≤—ã–π –º–µ–º —Å —Å–æ–±–∞–∫–æ–π-–∫—É—Å–∞–∫–æ–π?\",\n",
    " \"1_–ù–µ—Ç, –ø–æ–∫–∞–∂–∏\"\n",
    "]\n",
    "for i in range(1, len(test_data), 1):\n",
    "    input_data = test_data[:i]\n",
    "    labels = test_data[i]\n",
    "    print(f\"Label: '{labels}' | Input data: {input_data}\") \n",
    "    \n",
    "for i in range(1, len(test_data) // 2 + 1):\n",
    "    input_data = test_data[:i*2]\n",
    "    print(f\"Dialog: {input_data}\") \n",
    "print(\"---\")\n",
    "test_data_2 = test_data[:]\n",
    "test_data_2.pop(0)\n",
    "for i in range(1, len(test_data_2) // 2 +1):\n",
    "    input_data = test_data_2[:i*2]\n",
    "    print(f\"Dialog: {input_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–¢—ã –ø—Ä–∏–≥–ª–∞—à–∞–µ—à—å –º–µ–Ω—è –Ω–∞ —Å–≤–∏–¥–∞–Ω–∏–µ. –≠—Ç–æ —Ç–∞–∫ –º–∏–ª–æ. –ù–∞–ø–æ–º–Ω–∏, –∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç?',\n",
       "  '–ó–∞–±—É–¥—å –æ–± —ç—Ç–æ–º.'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '0_0_1',\n",
       " 'dataset_source': 'RUCornellMovieCorpusV1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_cornel_movie_corpus_dataloaders import RUCornellMovieCorpusV1\n",
    "    \n",
    "\n",
    "dataset = RUCornellMovieCorpusV1(\n",
    "    input_dataset_path='./datasets/cornell_movie_corpus/cornell_movie_corpus.txt'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–Ø –±—ã–ª?', '–¢—ã –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Ö–æ—Ç–µ–ª–∞ –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è —Å–æ –º–Ω–æ–π, –Ω–µ —Ç–∞–∫ –ª–∏?'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '11_1_1',\n",
       " 'dataset_source': 'RUCornellMovieCorpusV1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[–¢—ã –ø—Ä–∏–≥–ª–∞—à–∞–µ—à—å –º–µ–Ω—è –Ω–∞ —Å–≤–∏–¥–∞–Ω–∏–µ. –≠—Ç–æ —Ç–∞–∫ –º–∏–ª–æ...</td>\n",
       "      <td></td>\n",
       "      <td>0_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[–ë–æ–∂–µ, –µ—Å–ª–∏ –±—ã —Ç–æ–ª—å–∫–æ –º—ã –º–æ–≥–ª–∏ –Ω–∞–π—Ç–∏ –ö—ç—Ç –ø–∞—Ä–Ω—è...</td>\n",
       "      <td></td>\n",
       "      <td>1_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[–ö–∞–∫ –ø—Ä–æ–¥–≤–∏–≥–∞–µ—Ç—Å—è –Ω–∞—à –º–∞–ª–µ–Ω—å–∫–∏–π –ø–ª–∞–Ω \"–ù–∞–π–¥–∏ –¥–µ...</td>\n",
       "      <td></td>\n",
       "      <td>2_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[–í–æ—Ç —Ç–∞–∫., –ö—É–¥–∞?]</td>\n",
       "      <td></td>\n",
       "      <td>3_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[–£ —Ç–µ–±—è —á—Ç–æ-—Ç–æ –Ω–∞ —É–º–µ?, –Ø —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–ª, —á—Ç–æ –≤—ã ...</td>\n",
       "      <td></td>\n",
       "      <td>4_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110425</th>\n",
       "      <td>[–≠—Ç–æ –∫–æ–Ω—Ç—Ä–∞–±–∞–Ω–¥–∞. –ù–µ —Å–ø—Ä–∞—à–∏–≤–∞–π. –ù–æ —è —Ö–æ—Ç–µ–ª —Ç–µ–±...</td>\n",
       "      <td></td>\n",
       "      <td>51101_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110426</th>\n",
       "      <td>[–¢—ã —É—Ö–æ–¥–∏—à—å –æ—Ç –Ω–∞—Å?, –û –Ω–µ—Ç. –ú—ã –≤—Å–µ–≥–¥–∞ –±—É–¥–µ–º –≤–º...</td>\n",
       "      <td></td>\n",
       "      <td>51102_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110427</th>\n",
       "      <td>[–°–æ–≤–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª–æ–≤! –Ø —Ç–∞–∫ –Ω–µ—Ä–≤–Ω–∏—á–∞—é! –ß—Ç–æ, –µ—Å–ª–∏ ...</td>\n",
       "      <td></td>\n",
       "      <td>51103_0_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110428</th>\n",
       "      <td>[–°–æ–≤–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª–æ–≤! –Ø —Ç–∞–∫ –Ω–µ—Ä–≤–Ω–∏—á–∞—é! –ß—Ç–æ, –µ—Å–ª–∏ ...</td>\n",
       "      <td></td>\n",
       "      <td>51103_0_2</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110429</th>\n",
       "      <td>[–ü—Ä—è–º–æ –≤ –∞–¥. –®—É—á—É. –ì–¥–µ —ç—Ç–æ—Ç –∞–≤—Ç–æ–±—É—Å?, ]</td>\n",
       "      <td></td>\n",
       "      <td>51103_1_1</td>\n",
       "      <td>RUCornellMovieCorpusV1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110430 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context knowledge  \\\n",
       "0       [–¢—ã –ø—Ä–∏–≥–ª–∞—à–∞–µ—à—å –º–µ–Ω—è –Ω–∞ —Å–≤–∏–¥–∞–Ω–∏–µ. –≠—Ç–æ —Ç–∞–∫ –º–∏–ª–æ...             \n",
       "1       [–ë–æ–∂–µ, –µ—Å–ª–∏ –±—ã —Ç–æ–ª—å–∫–æ –º—ã –º–æ–≥–ª–∏ –Ω–∞–π—Ç–∏ –ö—ç—Ç –ø–∞—Ä–Ω—è...             \n",
       "2       [–ö–∞–∫ –ø—Ä–æ–¥–≤–∏–≥–∞–µ—Ç—Å—è –Ω–∞—à –º–∞–ª–µ–Ω—å–∫–∏–π –ø–ª–∞–Ω \"–ù–∞–π–¥–∏ –¥–µ...             \n",
       "3                                       [–í–æ—Ç —Ç–∞–∫., –ö—É–¥–∞?]             \n",
       "4       [–£ —Ç–µ–±—è —á—Ç–æ-—Ç–æ –Ω–∞ —É–º–µ?, –Ø —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–ª, —á—Ç–æ –≤—ã ...             \n",
       "...                                                   ...       ...   \n",
       "110425  [–≠—Ç–æ –∫–æ–Ω—Ç—Ä–∞–±–∞–Ω–¥–∞. –ù–µ —Å–ø—Ä–∞—à–∏–≤–∞–π. –ù–æ —è —Ö–æ—Ç–µ–ª —Ç–µ–±...             \n",
       "110426  [–¢—ã —É—Ö–æ–¥–∏—à—å –æ—Ç –Ω–∞—Å?, –û –Ω–µ—Ç. –ú—ã –≤—Å–µ–≥–¥–∞ –±—É–¥–µ–º –≤–º...             \n",
       "110427  [–°–æ–≤–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª–æ–≤! –Ø —Ç–∞–∫ –Ω–µ—Ä–≤–Ω–∏—á–∞—é! –ß—Ç–æ, –µ—Å–ª–∏ ...             \n",
       "110428  [–°–æ–≤–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª–æ–≤! –Ø —Ç–∞–∫ –Ω–µ—Ä–≤–Ω–∏—á–∞—é! –ß—Ç–æ, –µ—Å–ª–∏ ...             \n",
       "110429            [–ü—Ä—è–º–æ –≤ –∞–¥. –®—É—á—É. –ì–¥–µ —ç—Ç–æ—Ç –∞–≤—Ç–æ–±—É—Å?, ]             \n",
       "\n",
       "        sample_id          dataset_source  \n",
       "0           0_0_1  RUCornellMovieCorpusV1  \n",
       "1           1_0_1  RUCornellMovieCorpusV1  \n",
       "2           2_0_1  RUCornellMovieCorpusV1  \n",
       "3           3_0_1  RUCornellMovieCorpusV1  \n",
       "4           4_0_1  RUCornellMovieCorpusV1  \n",
       "...           ...                     ...  \n",
       "110425  51101_0_1  RUCornellMovieCorpusV1  \n",
       "110426  51102_0_1  RUCornellMovieCorpusV1  \n",
       "110427  51103_0_1  RUCornellMovieCorpusV1  \n",
       "110428  51103_0_2  RUCornellMovieCorpusV1  \n",
       "110429  51103_1_1  RUCornellMovieCorpusV1  \n",
       "\n",
       "[110430 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ru anekdots dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–ö–∞–∫ –≤–æ–¥–∏—á–∫–∞ ?',\n",
       "  '–ê —è –∑–¥–µ—Å—å –∫–∞–∫ –∂–µ–Ω—à–∏–Ω–∞ —Å–∏–∂—É, –∞ –Ω–µ –∫–∞–∫ —Ç–µ—Ä–º–æ–º–µ—Ç—Ä.'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '0_0_1',\n",
       " 'dataset_source': 'RUAnekdotsDialogsV1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_anekdots_dialogs_dataloaders import RUAnekdotsDialogsV1\n",
    "\n",
    "dataset = RUAnekdotsDialogsV1(\n",
    "    input_dataset_path='./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs.txt'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–í —Å—Ç—Ä–∞–Ω–µ –∫—É—á–∞ —Ö–æ—Ä–æ—à–µ–Ω—å–∫–∏—Ö –¥–µ–≤—É—à–µ–∫, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ö–æ—Ç—è—Ç –∑–∞–º—É–∂.',\n",
       "  '–û—Ç–∫—É–¥–∞ –∑–Ω–∞–µ—à—å?'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '40_0_1',\n",
       " 'dataset_source': 'RUAnekdotsDialogsV1'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[–ö–∞–∫ –≤–æ–¥–∏—á–∫–∞ ?, –ê —è –∑–¥–µ—Å—å –∫–∞–∫ –∂–µ–Ω—à–∏–Ω–∞ —Å–∏–∂—É, –∞ ...</td>\n",
       "      <td></td>\n",
       "      <td>0_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[–Ø –∑–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º –¥–∏–∞–≥–Ω–æ–∑ ... –ù–∞–≤–µ—Ä...</td>\n",
       "      <td></td>\n",
       "      <td>1_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–µ—Ñ–∏—Ü–∏—Ç –≤ –º–∞—Ä–∫–∏—Å—Ç—Å–∫–æ–º –ø–æ–Ω–∏–º–∞–Ω–∏–∏?, –≠...</td>\n",
       "      <td></td>\n",
       "      <td>2_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–µ—Ñ–∏—Ü–∏—Ç –≤ –º–∞—Ä–∫–∏—Å—Ç—Å–∫–æ–º –ø–æ–Ω–∏–º–∞–Ω–∏–∏?, –≠...</td>\n",
       "      <td></td>\n",
       "      <td>2_0_2</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[–≠—Ç–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å, –Ω–µ –¥–∞–Ω–Ω–∞—è –Ω–∞–º –≤ –æ...</td>\n",
       "      <td></td>\n",
       "      <td>2_1_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164769</th>\n",
       "      <td>[–ê–ª–ª–æ, –º–∏–ª–∏—Ü–∏—è?!, –î–∞!, –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–µ–∑–∂–∞–π—Ç–µ, –º–µ–Ω...</td>\n",
       "      <td></td>\n",
       "      <td>87718_0_3</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164770</th>\n",
       "      <td>[–î–∞!, –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–µ–∑–∂–∞–π—Ç–µ, –º–µ–Ω—è –Ω–∞—Å–∏–ª—É—é—Ç!]</td>\n",
       "      <td></td>\n",
       "      <td>87718_1_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164771</th>\n",
       "      <td>[–î–∞!, –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–µ–∑–∂–∞–π—Ç–µ, –º–µ–Ω—è –Ω–∞—Å–∏–ª—É—é—Ç!, –ö—É–¥–∞...</td>\n",
       "      <td></td>\n",
       "      <td>87718_1_2</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164772</th>\n",
       "      <td>[–ü–∞–ø, —è –≤ –ø—è—Ç–Ω–∏—Ü—É –Ω–∞ —Å–≤–∞–¥—å–±—É –∏–¥—É, –¥–∞–π –¥–µ–Ω–µ–≥., ...</td>\n",
       "      <td></td>\n",
       "      <td>87719_0_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164773</th>\n",
       "      <td>[–ü—è—Ç—å —Ç—ã—Å—è—á —Ö–≤–∞—Ç–∏—Ç?, –ù—É —Ç—ã —á–æ?! –ü–ª–∞—Ç—å–µ, —Ñ–∞—Ç–∞...]</td>\n",
       "      <td></td>\n",
       "      <td>87719_1_1</td>\n",
       "      <td>RUAnekdotsDialogsV1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164774 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context knowledge  \\\n",
       "0       [–ö–∞–∫ –≤–æ–¥–∏—á–∫–∞ ?, –ê —è –∑–¥–µ—Å—å –∫–∞–∫ –∂–µ–Ω—à–∏–Ω–∞ —Å–∏–∂—É, –∞ ...             \n",
       "1       [–Ø –∑–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –ø–æ—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º –¥–∏–∞–≥–Ω–æ–∑ ... –ù–∞–≤–µ—Ä...             \n",
       "2       [–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–µ—Ñ–∏—Ü–∏—Ç –≤ –º–∞—Ä–∫–∏—Å—Ç—Å–∫–æ–º –ø–æ–Ω–∏–º–∞–Ω–∏–∏?, –≠...             \n",
       "3       [–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–µ—Ñ–∏—Ü–∏—Ç –≤ –º–∞—Ä–∫–∏—Å—Ç—Å–∫–æ–º –ø–æ–Ω–∏–º–∞–Ω–∏–∏?, –≠...             \n",
       "4       [–≠—Ç–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å, –Ω–µ –¥–∞–Ω–Ω–∞—è –Ω–∞–º –≤ –æ...             \n",
       "...                                                   ...       ...   \n",
       "164769  [–ê–ª–ª–æ, –º–∏–ª–∏—Ü–∏—è?!, –î–∞!, –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–µ–∑–∂–∞–π—Ç–µ, –º–µ–Ω...             \n",
       "164770          [–î–∞!, –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–µ–∑–∂–∞–π—Ç–µ, –º–µ–Ω—è –Ω–∞—Å–∏–ª—É—é—Ç!]             \n",
       "164771  [–î–∞!, –ë—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏–µ–∑–∂–∞–π—Ç–µ, –º–µ–Ω—è –Ω–∞—Å–∏–ª—É—é—Ç!, –ö—É–¥–∞...             \n",
       "164772  [–ü–∞–ø, —è –≤ –ø—è—Ç–Ω–∏—Ü—É –Ω–∞ —Å–≤–∞–¥—å–±—É –∏–¥—É, –¥–∞–π –¥–µ–Ω–µ–≥., ...             \n",
       "164773   [–ü—è—Ç—å —Ç—ã—Å—è—á —Ö–≤–∞—Ç–∏—Ç?, –ù—É —Ç—ã —á–æ?! –ü–ª–∞—Ç—å–µ, —Ñ–∞—Ç–∞...]             \n",
       "\n",
       "        sample_id       dataset_source  \n",
       "0           0_0_1  RUAnekdotsDialogsV1  \n",
       "1           1_0_1  RUAnekdotsDialogsV1  \n",
       "2           2_0_1  RUAnekdotsDialogsV1  \n",
       "3           2_0_2  RUAnekdotsDialogsV1  \n",
       "4           2_1_1  RUAnekdotsDialogsV1  \n",
       "...           ...                  ...  \n",
       "164769  87718_0_3  RUAnekdotsDialogsV1  \n",
       "164770  87718_1_1  RUAnekdotsDialogsV1  \n",
       "164771  87718_1_2  RUAnekdotsDialogsV1  \n",
       "164772  87719_0_1  RUAnekdotsDialogsV1  \n",
       "164773  87719_1_1  RUAnekdotsDialogsV1  \n",
       "\n",
       "[164774 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flibusta_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–ü–æ—á–µ–º—É —Ç–µ–±—è –æ—Ç–ø—É—Å—Ç–∏–ª–∏, –∞ –ö–∏—Ä–∏–ª–ª–∞ –Ω–µ—Ç?',\n",
       "  '–Ø —Å–±–µ–∂–∞–ª, –∏–∑ –≥–æ—Ä—è—â–µ–π –≥–æ—Å—Ç–∏–Ω–∏—Ü—ã.'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '0_0_1',\n",
       " 'dataset_source': 'RUFlibustaDialogsV1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_flibusta_dialogs_dataloaders import RUFlibustaDialogsV1\n",
    "\n",
    "dataset = RUFlibustaDialogsV1(\n",
    "    input_dataset_path='./datasets/flibusta_dialogues/flibusta_dialogues.txt'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–ü—Ä—è—Ç–∞–ª–∞—Å—å —É —Å–µ–±—è –≤ –Ω–æ—Ä–µ, —á—Ç–æ–±—ã –∑–∞–ª–∏–∑–∞—Ç—å —Ä–∞–Ω—ã',\n",
       "  '–Ø –≤—Å–µ–≥–¥–∞ –≥–æ–≤–æ—Ä–∏–ª, —á—Ç–æ –≤ —Ç–µ–±–µ –µ—Å—Ç—å —á—Ç–æ —Ç–æ –æ—Ç –ª–∏—Å—ã'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '74_1_1',\n",
       " 'dataset_source': 'RUFlibustaDialogsV1'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–Ø –±—É–¥—É –∫—É—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à—É —Ä–∞–±–æ—Ç—É –æ—Ç –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–æ–≤.',\n",
       "  '–ú—É–∂–∏–∫–æ–≤ —É –Ω–∞—Å —Ç–∞–º –±–æ–ª—å—à–µ –Ω–µ—Ç, —á—Ç–æ –ª–∏?'],\n",
       " 'knowledge': '',\n",
       " 'sample_id': '153_0_1',\n",
       " 'dataset_source': 'RUFlibustaDialogsV1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuBQ 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 0,\n",
       " 'ru_wiki_pageid': 58311,\n",
       " 'text': '–¶–°–ö–ê ‚Äî —Å–æ–≤–µ—Ç—Å–∫–∏–π –∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ö–æ–∫–∫–µ–π–Ω—ã–π –∫–ª—É–± –∏–∑ –ú–æ—Å–∫–≤—ã, –≤—ã—Å—Ç—É–ø–∞—é—â–∏–π –≤ –ö–æ–Ω—Ç–∏–Ω–µ–Ω—Ç–∞–ª—å–Ω–æ–π —Ö–æ–∫–∫–µ–π–Ω–æ–π –ª–∏–≥–µ. –û—Å–Ω–æ–≤–∞–Ω –≤ 1946 –≥–æ–¥—É –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º –¶–î–ö–ê (–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –¥–æ–º –ö—Ä–∞—Å–Ω–æ–π –ê—Ä–º–∏–∏). –í 1951 –≥–æ–¥—É –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –≤ –¶–î–°–ê (–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –¥–æ–º –°–æ–≤–µ—Ç—Å–∫–æ–π –ê—Ä–º–∏–∏), –∞ –≤ 1954 –≤ –¶–°–ö –ú–û (–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –∫–ª—É–± –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ –æ–±–æ—Ä–æ–Ω—ã), –ø–æ–¥ –∫–æ—Ç–æ—Ä—ã–º –≤—ã—Å—Ç—É–ø–∞–ª –¥–æ 1959 –≥–æ–¥–∞, –∏ —Å —Ç–µ—Ö –ø–æ—Ä –Ω–æ—Å–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –¶–°–ö–ê (–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π –ö–ª—É–± –ê—Ä–º–∏–∏).'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json\n",
    "import json\n",
    "data_dev = open('./datasets/ru_bq20/RuBQ_2.0_dev.json', 'r',) \n",
    "data_dev = json.load(data_dev)\n",
    "\n",
    "data_test = open('./datasets/ru_bq20/RuBQ_2.0_test.json', 'r')\n",
    "data_test = json.load(data_test)\n",
    "\n",
    "data_paragraphs = open('./datasets/ru_bq20/RuBQ_2.0_paragraphs.json', 'r')\n",
    "data_paragraphs = json.load(data_paragraphs)\n",
    "data_paragraphs = {item['uid']: item for item in data_paragraphs}\n",
    "# data_dev[0]\n",
    "data_paragraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'ru_wiki_pageid', 'text'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paragraphs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 4,\n",
       " 'question_text': '–ö–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∑–Ω–∞–º–µ–Ω–∏—Ç—ã–π –æ—Å—Ç—Ä–æ–≤ –ü–∞—Å—Ö–∏?',\n",
       " 'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q14452 wdt:P17 ?answer\\n}',\n",
       " 'answer_text': '–ß–∏–ª–∏',\n",
       " 'question_uris': ['http://www.wikidata.org/entity/Q14452'],\n",
       " 'question_props': ['wdt:P17'],\n",
       " 'answers': [{'type': 'uri',\n",
       "   'label': '–ß–∏–ª–∏',\n",
       "   'value': 'http://www.wikidata.org/entity/Q298',\n",
       "   'wd_names': {'ru': ['–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ß–∏–ª–∏', '–ß–∏–ª–∏'],\n",
       "    'en': ['Chile',\n",
       "     'Rep√∫blica de Chile',\n",
       "     'Republic of Chile',\n",
       "     'cl',\n",
       "     'Republica de Chile',\n",
       "     'CHI',\n",
       "     'üá®üá±']},\n",
       "   'wp_names': ['–ß–∏–ª–∏–π—Å–∫–∞—è']}],\n",
       " 'paragraphs_uids': {'with_answer': [10785, 10782, 10783],\n",
       "  'all_related': [10782,\n",
       "   10783,\n",
       "   10784,\n",
       "   10785,\n",
       "   10786,\n",
       "   53027,\n",
       "   53028,\n",
       "   53029,\n",
       "   53030,\n",
       "   53031,\n",
       "   53032,\n",
       "   53033,\n",
       "   53034,\n",
       "   53035,\n",
       "   53036,\n",
       "   35776,\n",
       "   35777,\n",
       "   35778,\n",
       "   35779,\n",
       "   35780,\n",
       "   51707,\n",
       "   51708,\n",
       "   51709,\n",
       "   51710,\n",
       "   51711]},\n",
       " 'tags': ['1-hop'],\n",
       " 'RuBQ_version': '1.0',\n",
       " 'question_eng': 'Which country does the famous Easter island belong to?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 0,\n",
       " 'question_text': '–ß—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å —Ü—É–Ω–∞–º–∏?',\n",
       " 'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q8070 wdt:P828 ?answer\\n}',\n",
       " 'answer_text': '–ó–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–µ',\n",
       " 'question_uris': ['http://www.wikidata.org/entity/Q8070'],\n",
       " 'question_props': ['wdt:P828'],\n",
       " 'answers': [{'type': 'uri',\n",
       "   'label': '–∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–µ',\n",
       "   'value': 'http://www.wikidata.org/entity/Q7944',\n",
       "   'wd_names': {'ru': ['–∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–µ', '“ó–∏—Ä —Ç–µ—Ç—Ä”ô–≤–µ'],\n",
       "    'en': ['seism',\n",
       "     'earthquake',\n",
       "     'seismic activity',\n",
       "     'fore shocks',\n",
       "     'tremor',\n",
       "     'earthquakes',\n",
       "     'earth quake',\n",
       "     'earthtemblor',\n",
       "     'foreshock',\n",
       "     'aftershock',\n",
       "     'quake',\n",
       "     'temblor',\n",
       "     'earth temblor',\n",
       "     'foreshocks',\n",
       "     'after shocks',\n",
       "     'earth quakes',\n",
       "     'after shock',\n",
       "     'earthtremor',\n",
       "     'convulsion',\n",
       "     'earth tremor',\n",
       "     'shock',\n",
       "     'fore shock',\n",
       "     'aftershocks']},\n",
       "   'wp_names': ['–∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏—è–º']},\n",
       "  {'type': 'uri',\n",
       "   'label': '–º–µ—Ç–µ–æ—Ä–∏—Ç',\n",
       "   'value': 'http://www.wikidata.org/entity/Q60186',\n",
       "   'wd_names': {'ru': ['–º–µ—Ç–µ–æ—Ä–∏—Ç', '–ú–µ—Ç–µ–æ—Ä–∏—Ç—ã', '–ê—ç—Ä–æ–ª–∏—Ç—ã'],\n",
       "    'en': ['shooting star', 'meteorite']},\n",
       "   'wp_names': []},\n",
       "  {'type': 'uri',\n",
       "   'label': '–æ–ø–æ–ª–∑–µ–Ω—å',\n",
       "   'value': 'http://www.wikidata.org/entity/Q167903',\n",
       "   'wd_names': {'ru': ['–æ–ø–æ–ª–∑–µ–Ω—å', '–æ–ø–æ–ª–∑–Ω–∏'],\n",
       "    'en': ['Rock avalanche', 'landslide', 'landslip']},\n",
       "   'wp_names': ['–æ–ø–æ–ª–∑–Ω–∏', '–æ–ø–æ–ª–∑–Ω—è–º–∏']},\n",
       "  {'type': 'uri',\n",
       "   'label': '–ü—Ä–æ–µ–∫—Ç Seal',\n",
       "   'value': 'http://www.wikidata.org/entity/Q2580904',\n",
       "   'wd_names': {'ru': ['–ü—Ä–æ–µ–∫—Ç Seal'], 'en': ['tsunami bomb']},\n",
       "   'wp_names': []},\n",
       "  {'type': 'uri',\n",
       "   'label': '–ø–æ–¥–≤–æ–¥–Ω—ã–π –æ–ø–æ–ª–∑–µ–Ω—å',\n",
       "   'value': 'http://www.wikidata.org/entity/Q5975740',\n",
       "   'wd_names': {'ru': [],\n",
       "    'en': ['undersea landslide',\n",
       "     'submarine landslide',\n",
       "     'underwater landslide']},\n",
       "   'wp_names': []},\n",
       "  {'type': 'uri',\n",
       "   'label': '–∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ –≤—É–ª–∫–∞–Ω–∞',\n",
       "   'value': 'http://www.wikidata.org/entity/Q7692360',\n",
       "   'wd_names': {'ru': ['–§—Ä–µ–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ',\n",
       "     '–í—É–ª–∫–∞–Ω–∏—á–µ—Å–∫–∏–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏—è',\n",
       "     '–°—Ç—Ä–æ–º–±–æ–ª–∏–∞–Ω—Å–∫–æ–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ',\n",
       "     '–∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ –≤—É–ª–∫–∞–Ω–∞',\n",
       "     '–ì–∞–≤–∞–π—Å–∫–æ–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ',\n",
       "     '–ì–∞–∑–æ–≤–æ–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ',\n",
       "     '–í—É–ª–∫–∞–Ω–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ',\n",
       "     '–ü–µ–ª–µ–π—Å–∫–æ–µ –∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ'],\n",
       "    'en': ['volcano eruption', 'volcanic eruption', 'eruption']},\n",
       "   'wp_names': ['–∏–∑–≤–µ—Ä–∂–µ–Ω–∏—è –≤—É–ª–∫–∞–Ω–∞']}],\n",
       " 'paragraphs_uids': {'with_answer': [35622],\n",
       "  'all_related': [35622,\n",
       "   35623,\n",
       "   35624,\n",
       "   35625,\n",
       "   35626,\n",
       "   35632,\n",
       "   35633,\n",
       "   35634,\n",
       "   35635,\n",
       "   35636,\n",
       "   35637,\n",
       "   35638,\n",
       "   35639,\n",
       "   35640,\n",
       "   35641,\n",
       "   35642,\n",
       "   35643,\n",
       "   35644,\n",
       "   35645,\n",
       "   35646,\n",
       "   35647,\n",
       "   35648,\n",
       "   35649,\n",
       "   35650,\n",
       "   35651]},\n",
       " 'tags': ['1-hop'],\n",
       " 'RuBQ_version': '1.0',\n",
       " 'question_eng': 'What can cause a tsunami?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'question_text', 'query', 'answer_text', 'question_uris', 'question_props', 'answers', 'paragraphs_uids', 'tags', 'RuBQ_version', 'question_eng'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data_dev[10]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('–ö–∞–∫ –Ω–∞–∑—ã–≤–∞–ª–∞—Å—å —Å—Ç–æ–ª–∏—Ü–∞ –ö—Ä—ã–º—Å–∫–æ–≥–æ —Ö–∞–Ω—Å—Ç–≤–∞?',\n",
       " '–ë–∞—Ö—á–∏—Å–∞—Ä–∞–π',\n",
       " '–ü—Ä–∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –≤ –ö—Ä—ã–º—É –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ –æ—Ç –û—Ä–¥—ã –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞ —Å—Ç–æ–ª–∏—Ü–∞ –±—ã–ª–∞ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ —É–∫—Ä–µ–ø–ª—ë–Ω–Ω—É—é –≥–æ—Ä–Ω—É—é –∫—Ä–µ–ø–æ—Å—Ç—å –ö—ã—Ä–∫-–ï—Ä, –∑–∞—Ç–µ–º –≤ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–π –≤ –¥–æ–ª–∏–Ω–µ —É –ø–æ–¥–Ω–æ–∂–∏—è –ö—ã—Ä–∫-–ï—Ä–∞ –°–∞–ª–∞—á–∏–∫ –∏, –Ω–∞–∫–æ–Ω–µ—Ü, –≤ 1532 –≥–æ–¥—É –≤–æ –≤–Ω–æ–≤—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≥–æ—Ä–æ–¥ –ë–∞—Ö—á–∏—Å–∞—Ä–∞–π.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_paragraph_id = sample['paragraphs_uids']['with_answer'][0]\n",
    "info_paragraph = data_paragraphs[info_paragraph_id]['text']\n",
    "\n",
    "sample['question_text'], sample['answer_text'], info_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = {}\n",
    "alldata['questions'] = data_dev + data_test\n",
    "alldata['paragraphs'] = data_paragraphs\n",
    "\n",
    "# save json\n",
    "with open('./datasets/ru_bq20/RuBQ_2.0_all.json', 'w', encoding='utf-8') as outfile:\n",
    "\tjson.dump(alldata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 4,\n",
       " 'question_text': '–ö–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∑–Ω–∞–º–µ–Ω–∏—Ç—ã–π –æ—Å—Ç—Ä–æ–≤ –ü–∞—Å—Ö–∏?',\n",
       " 'query': 'SELECT ?answer \\nWHERE {\\n  wd:Q14452 wdt:P17 ?answer\\n}',\n",
       " 'answer_text': '–ß–∏–ª–∏',\n",
       " 'question_uris': ['http://www.wikidata.org/entity/Q14452'],\n",
       " 'question_props': ['wdt:P17'],\n",
       " 'answers': [{'type': 'uri',\n",
       "   'label': '–ß–∏–ª–∏',\n",
       "   'value': 'http://www.wikidata.org/entity/Q298',\n",
       "   'wd_names': {'ru': ['–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ß–∏–ª–∏', '–ß–∏–ª–∏'],\n",
       "    'en': ['Chile',\n",
       "     'Rep√∫blica de Chile',\n",
       "     'Republic of Chile',\n",
       "     'cl',\n",
       "     'Republica de Chile',\n",
       "     'CHI',\n",
       "     'üá®üá±']},\n",
       "   'wp_names': ['–ß–∏–ª–∏–π—Å–∫–∞—è']}],\n",
       " 'paragraphs_uids': {'with_answer': [10785, 10782, 10783],\n",
       "  'all_related': [10782,\n",
       "   10783,\n",
       "   10784,\n",
       "   10785,\n",
       "   10786,\n",
       "   53027,\n",
       "   53028,\n",
       "   53029,\n",
       "   53030,\n",
       "   53031,\n",
       "   53032,\n",
       "   53033,\n",
       "   53034,\n",
       "   53035,\n",
       "   53036,\n",
       "   35776,\n",
       "   35777,\n",
       "   35778,\n",
       "   35779,\n",
       "   35780,\n",
       "   51707,\n",
       "   51708,\n",
       "   51709,\n",
       "   51710,\n",
       "   51711]},\n",
       " 'tags': ['1-hop'],\n",
       " 'RuBQ_version': '1.0',\n",
       " 'question_eng': 'Which country does the famous Easter island belong to?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.dumps(alldata))['questions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–ö–∞–∫–æ–π —Å—Ç—Ä–∞–Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∑–Ω–∞–º–µ–Ω–∏—Ç—ã–π –æ—Å—Ç—Ä–æ–≤ –ü–∞—Å—Ö–∏?'],\n",
       " 'knowledge': ['–æ—Å—Ç—Ä–æ–≤ –ü–∞—Å—Ö–∏ (–Ω–∏–¥–µ—Ä–ª. Paasch-Eyland; –∏—Å–ø. Isla de Pascua), –Ω–∞–∑–≤–∞–Ω–Ω—ã–π —Ç–∞–∫ –≥–æ–ª–ª–∞–Ω–¥—Å–∫–∏–º –º–æ—Ä–µ–ø–ª–∞–≤–∞—Ç–µ–ª–µ–º –Ø–∫–æ–±–æ–º –†–æ–≥–≥–µ–≤–µ–Ω–æ–º, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω –æ—Ç–∫—Ä—ã–ª –µ–≥–æ –≤ –¥–µ–Ω—å –ü–∞—Å—Ö–∏ 1722 –≥–æ–¥–∞.–û—á–µ–Ω—å —á–∞—Å—Ç–æ –æ—Å—Ç—Ä–æ–≤ –ü–∞—Å—Ö–∏ –Ω–∞–∑—ã–≤–∞—é—Ç –†–∞–ø–∞–Ω—É–∏ (–≤ –ø–µ—Ä–µ–≤–æ–¥–µ ‚Äî ¬´–ë–æ–ª—å—à–æ–π –†–∞–ø–∞¬ª). –¢–∞–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Å—Ç—Ä–æ–≤ –ø–æ–ª—É—á–∏–ª –±–ª–∞–≥–æ–¥–∞—Ä—è —Ç–∞–∏—Ç—è–Ω—Å–∫–∏–º –º–æ—Ä–µ–ø–ª–∞–≤–∞—Ç–µ–ª—è–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–≤—à–∏–º –µ–≥–æ, —á—Ç–æ–±—ã —Ä–∞–∑–ª–∏—á–∞—Ç—å –æ—Å—Ç—Ä–æ–≤ –ü–∞—Å—Ö–∏ –∏ –æ—Å—Ç—Ä–æ–≤ –†–∞–ø–∞-–ò—Ç–∏ (–≤ –ø–µ—Ä–µ–≤–æ–¥–µ ‚Äî ¬´–ú–∞–ª—ã–π –†–∞–ø–∞¬ª), –ª–µ–∂–∞—â–∏–π –≤ 650 –∫–º –∫ —é–≥—É –æ—Ç –¢–∞–∏—Ç–∏, –∏ –∏–º–µ—é—â–∏–π —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –Ω–∏–º. –í –∞–≤–≥—É—Å—Ç–µ 2018 –≥–æ–¥–∞ –≤–ª–∞—Å—Ç–∏ —Å—Ç—Ä–∞–Ω—ã, —Å–æ–≥–ª–∞—Å–Ω–æ –£–∫–∞–∑—É –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –ß–∏–ª–∏, —É—Å–∫–æ—Ä–∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ –æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–∏ –û—Å—Ç—Ä–æ–≤–∞ –ü–∞—Å—Ö–∏ –≤ –†–∞–ø–∞-–ù—É–∏.'],\n",
       " 'sample_id': '0',\n",
       " 'label': '–ß–∏–ª–∏',\n",
       " 'dataset_source': 'RURubq20V1'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_rubq20_dataloaders import RURubq20V1\n",
    "\n",
    "\n",
    "dataset = RURubq20V1(\n",
    "    input_dataset_path='./datasets/ru_bq20/RuBQ_2.0_all.json'\n",
    ")\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['–ü—Ä–∏ –∫–∞–∫–æ–º —Ä–æ—Å—Å–∏–π—Å–∫–æ–º –º–æ–Ω–∞—Ä—Ö–µ –≤–æ–∑–Ω–∏–∫ –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –ú—É–∑–µ–π –≠—Ä–º–∏—Ç–∞–∂?'],\n",
       " 'knowledge': ['–°–≤–æ—é –∏—Å—Ç–æ—Ä–∏—é –º—É–∑–µ–π –Ω–∞—á–∏–Ω–∞–ª —Å –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π –∏—Å–∫—É—Å—Å—Ç–≤–∞, –ø—Ä–∏–æ–±—Ä–µ—Ç—ë–Ω–Ω—ã—Ö –≤ —á–∞—Å—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –∏–º–ø–µ—Ä–∞—Ç—Ä–∏—Ü–µ–π –ï–∫–∞—Ç–µ—Ä–∏–Ω–æ–π II. –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ —ç—Ç–æ —Å–æ–±—Ä–∞–Ω–∏–µ —Ä–∞–∑–º–µ—â–∞–ª–æ—Å—å –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–º –¥–≤–æ—Ä—Ü–æ–≤–æ–º —Ñ–ª–∏–≥–µ–ª–µ ‚Äî –≠—Ä–º–∏—Ç–∞–∂–µ (–æ—Ç —Ñ—Ä. ermitage ‚Äî –º–µ—Å—Ç–æ —É–µ–¥–∏–Ω–µ–Ω–∏—è, –∫–µ–ª—å—è, –ø—Ä–∏—é—Ç –æ—Ç—à–µ–ª—å–Ω–∏–∫–∞, –∑–∞—Ç–≤–æ—Ä–Ω–∏—á–µ—Å—Ç–≤–æ; –Ω—ã–Ω–µ –ú–∞–ª—ã–π –≠—Ä–º–∏—Ç–∞–∂) ‚Äî –æ—Ç–∫—É–¥–∞ –∏ –∑–∞–∫—Ä–µ–ø–∏–ª–æ—Å—å –æ–±—â–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±—É–¥—É—â–µ–≥–æ –º—É–∑–µ—è. –í 1852 –≥–æ–¥—É –∏–∑ —Å–∏–ª—å–Ω–æ —Ä–∞–∑—Ä–æ—Å—à–µ–π—Å—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –±—ã–ª —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –∏ –æ—Ç–∫—Ä—ã—Ç –¥–ª—è –ø–æ—Å–µ—â–µ–Ω–∏—è –ø—É–±–ª–∏—á–Ω—ã–π –º—É–∑–µ–π, —Ä–∞—Å–ø–æ–ª–æ–∂–∏–≤—à–∏–π—Å—è –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–º –∑–¥–∞–Ω–∏–∏ –ù–æ–≤–æ–≥–æ –≠—Ä–º–∏—Ç–∞–∂–∞.'],\n",
       " 'sample_id': '100',\n",
       " 'label': '–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ II',\n",
       " 'dataset_source': 'RURubq20V1'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd    \n",
    "\n",
    "train_path = \"./datasets/parus/train.jsonl\"\n",
    "valid_path = \"./datasets/parus/val.jsonl\"\n",
    "test_path = \"./datasets/parus/test.jsonl\"\n",
    "train_dataset = pd.read_json(train_path, lines=True)\n",
    "valid_dataset = pd.read_json(valid_path, lines=True)\n",
    "test_dataset = pd.read_json(test_path, lines=True)\n",
    "dataset = pd.concat([train_dataset, valid_dataset])\n",
    "dataset.to_csv(\"./datasets/parus/parus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>choice1</th>\n",
       "      <th>choice2</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ú–æ—ë —Ç–µ–ª–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç–µ–Ω—å –Ω–∞ —Ç—Ä–∞–≤—É.</td>\n",
       "      <td>–°–æ–ª–Ω—Ü–µ —É–∂–µ –ø–æ–¥–Ω—è–ª–æ—Å—å.</td>\n",
       "      <td>–¢—Ä–∞–≤–∞ —É–∂–µ –ø–æ–¥—Å—Ç—Ä–∏–∂–µ–Ω–∞.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω–∞ —Å–Ω–∏—Å—Ö–æ–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–Ω–æ—Å–∏–ª–∞—Å—å –∫ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É ...</td>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω–∞ –∑–Ω–∞–ª–∞, —á—Ç–æ –µ—ë –ø–æ–¥—Ä—É–≥–∞ –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç —Ç—Ä—É–¥–Ω...</td>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω–∞ —á—É–≤—Å—Ç–≤–æ–≤–∞–ª–∞, —á—Ç–æ –ø–æ–¥—Ä—É–≥–∞ –ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—ë...</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω—ã –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –ø–æ–ø–∏—Ç—å –∫–æ—Ñ–µ.</td>\n",
       "      <td>–ò—Ö –∫–∞—Ñ–µ –æ—Ç–∫—Ä—ã–ª–æ—Å—å –≤ –Ω–æ–≤–æ–º –º–µ—Å—Ç–µ.</td>\n",
       "      <td>–ò–º —Ö–æ—Ç–µ–ª–æ—Å—å –ø–µ—Ä–µ—Å–µ—á—å—Å—è –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º.</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ë–µ–≥—É–Ω—å—è –±—ã–ª–∞ –≤ —à–æ—Ä—Ç–∞—Ö.</td>\n",
       "      <td>–ü—Ä–æ–≥–Ω–æ–∑ –æ–±–µ—â–∞–ª –≤—ã—Å–æ–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É.</td>\n",
       "      <td>–û–Ω–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–ª–∞ –±–µ–∂–∞—Ç—å –≤–¥–æ–ª—å –ø–ª—è–∂–∞.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ì–æ—Å—Ç–∏ –≤–µ—á–µ—Ä–∏–Ω–∫–∏ –ø—Ä—è—Ç–∞–ª–∏—Å—å –∑–∞ –¥–∏–≤–∞–Ω–æ–º.</td>\n",
       "      <td>–≠—Ç–æ –±—ã–ª–∞ –≤–µ—á–µ—Ä–∏–Ω–∫–∞-—Å—é—Ä–ø—Ä–∏–∑.</td>\n",
       "      <td>–≠—Ç–æ –±—ã–ª –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è.</td>\n",
       "      <td>cause</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0                –ú–æ—ë —Ç–µ–ª–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç–µ–Ω—å –Ω–∞ —Ç—Ä–∞–≤—É.   \n",
       "1  –ñ–µ–Ω—â–∏–Ω–∞ —Å–Ω–∏—Å—Ö–æ–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–Ω–æ—Å–∏–ª–∞—Å—å –∫ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É ...   \n",
       "2                   –ñ–µ–Ω—â–∏–Ω—ã –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –ø–æ–ø–∏—Ç—å –∫–æ—Ñ–µ.   \n",
       "3                             –ë–µ–≥—É–Ω—å—è –±—ã–ª–∞ –≤ —à–æ—Ä—Ç–∞—Ö.   \n",
       "4              –ì–æ—Å—Ç–∏ –≤–µ—á–µ—Ä–∏–Ω–∫–∏ –ø—Ä—è—Ç–∞–ª–∏—Å—å –∑–∞ –¥–∏–≤–∞–Ω–æ–º.   \n",
       "\n",
       "                                             choice1  \\\n",
       "0                              –°–æ–ª–Ω—Ü–µ —É–∂–µ –ø–æ–¥–Ω—è–ª–æ—Å—å.   \n",
       "1  –ñ–µ–Ω—â–∏–Ω–∞ –∑–Ω–∞–ª–∞, —á—Ç–æ –µ—ë –ø–æ–¥—Ä—É–≥–∞ –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç —Ç—Ä—É–¥–Ω...   \n",
       "2                   –ò—Ö –∫–∞—Ñ–µ –æ—Ç–∫—Ä—ã–ª–æ—Å—å –≤ –Ω–æ–≤–æ–º –º–µ—Å—Ç–µ.   \n",
       "3                –ü—Ä–æ–≥–Ω–æ–∑ –æ–±–µ—â–∞–ª –≤—ã—Å–æ–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É.   \n",
       "4                        –≠—Ç–æ –±—ã–ª–∞ –≤–µ—á–µ—Ä–∏–Ω–∫–∞-—Å—é—Ä–ø—Ä–∏–∑.   \n",
       "\n",
       "                                             choice2 question  label  idx  \n",
       "0                             –¢—Ä–∞–≤–∞ —É–∂–µ –ø–æ–¥—Å—Ç—Ä–∏–∂–µ–Ω–∞.    cause      0    0  \n",
       "1  –ñ–µ–Ω—â–∏–Ω–∞ —á—É–≤—Å—Ç–≤–æ–≤–∞–ª–∞, —á—Ç–æ –ø–æ–¥—Ä—É–≥–∞ –ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—ë...    cause      0    1  \n",
       "2              –ò–º —Ö–æ—Ç–µ–ª–æ—Å—å –ø–µ—Ä–µ—Å–µ—á—å—Å—è –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º.    cause      1    2  \n",
       "3                –û–Ω–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–ª–∞ –±–µ–∂–∞—Ç—å –≤–¥–æ–ª—å –ø–ª—è–∂–∞.    cause      0    3  \n",
       "4                             –≠—Ç–æ –±—ã–ª –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è.    cause      0    4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./datasets/parus/parus.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[–ú–æ—ë —Ç–µ–ª–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç–µ–Ω—å –Ω–∞ —Ç—Ä–∞–≤—É.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–°–æ–ª–Ω—Ü–µ —É–∂–µ –ø–æ–¥–Ω—è–ª–æ—Å—å.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[–ñ–µ–Ω—â–∏–Ω–∞ —Å–Ω–∏—Å—Ö–æ–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–Ω–æ—Å–∏–ª–∞—Å—å –∫ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–ñ–µ–Ω—â–∏–Ω–∞ –∑–Ω–∞–ª–∞, —á—Ç–æ –µ—ë –ø–æ–¥—Ä—É–≥–∞ –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç —Ç—Ä—É–¥–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[–ñ–µ–Ω—â–∏–Ω—ã –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –ø–æ–ø–∏—Ç—å –∫–æ—Ñ–µ.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–ò–º —Ö–æ—Ç–µ–ª–æ—Å—å –ø–µ—Ä–µ—Å–µ—á—å—Å—è –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[–ë–µ–≥—É–Ω—å—è –±—ã–ª–∞ –≤ —à–æ—Ä—Ç–∞—Ö.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–ü—Ä–æ–≥–Ω–æ–∑ –æ–±–µ—â–∞–ª –≤—ã—Å–æ–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[–ì–æ—Å—Ç–∏ –≤–µ—á–µ—Ä–∏–Ω–∫–∏ –ø—Ä—è—Ç–∞–ª–∏—Å—å –∑–∞ –¥–∏–≤–∞–Ω–æ–º.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–≠—Ç–æ –±—ã–ª–∞ –≤–µ—á–µ—Ä–∏–Ω–∫–∞-—Å—é—Ä–ø—Ä–∏–∑.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[–í —É—à–∞—Ö –∑–≤–µ–Ω–µ–ª–æ.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>95</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–Ø —Ö–æ–¥–∏–ª –Ω–∞ –∫–æ–Ω—Ü–µ—Ä—Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[–Ø –ø—Ä–∏–±—Ä–∞–ª–∞—Å—å –¥–æ–º–∞.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>96</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–Ø –∂–¥–∞–ª–∞ –¥—Ä—É–∑–µ–π.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[–ê–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è –ø–æ–≤—Ä–µ–¥–∏–ª–∞ –º–æ–π –±–∞–≥–∞–∂.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>97</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–û–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –º–Ω–µ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—é.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[–ß–∏–Ω–∏—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –±—ã–ª–æ –±—ã —Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>98</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–Ø –∫—É–ø–∏–ª –Ω–æ–≤—ã–π.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[–ñ–µ–Ω—â–∏–Ω–∞ –±—ã–ª–∞ –≤ –ø–ª–æ—Ö–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>99</td>\n",
       "      <td>RUParusDatasetV1</td>\n",
       "      <td>–û–Ω–∞ –ø–æ–ø—Ä–æ—Å–∏–ª–∞ –ø–æ–¥—Ä—É–≥—É –æ—Å—Ç–∞–≤–∏—Ç—å –µ—ë –≤ –ø–æ–∫–æ–µ.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context knowledge sample_id  \\\n",
       "0                [–ú–æ—ë —Ç–µ–ª–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç–µ–Ω—å –Ω–∞ —Ç—Ä–∞–≤—É.]        []         0   \n",
       "1    [–ñ–µ–Ω—â–∏–Ω–∞ —Å–Ω–∏—Å—Ö–æ–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–Ω–æ—Å–∏–ª–∞—Å—å –∫ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É...        []         1   \n",
       "2                   [–ñ–µ–Ω—â–∏–Ω—ã –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –ø–æ–ø–∏—Ç—å –∫–æ—Ñ–µ.]        []         2   \n",
       "3                             [–ë–µ–≥—É–Ω—å—è –±—ã–ª–∞ –≤ —à–æ—Ä—Ç–∞—Ö.]        []         3   \n",
       "4              [–ì–æ—Å—Ç–∏ –≤–µ—á–µ—Ä–∏–Ω–∫–∏ –ø—Ä—è—Ç–∞–ª–∏—Å—å –∑–∞ –¥–∏–≤–∞–Ω–æ–º.]        []         4   \n",
       "..                                                 ...       ...       ...   \n",
       "495                                  [–í —É—à–∞—Ö –∑–≤–µ–Ω–µ–ª–æ.]        []        95   \n",
       "496                               [–Ø –ø—Ä–∏–±—Ä–∞–ª–∞—Å—å –¥–æ–º–∞.]        []        96   \n",
       "497                [–ê–≤–∏–∞–∫–æ–º–ø–∞–Ω–∏—è –ø–æ–≤—Ä–µ–¥–∏–ª–∞ –º–æ–π –±–∞–≥–∞–∂.]        []        97   \n",
       "498         [–ß–∏–Ω–∏—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –±—ã–ª–æ –±—ã —Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ.]        []        98   \n",
       "499                [–ñ–µ–Ω—â–∏–Ω–∞ –±—ã–ª–∞ –≤ –ø–ª–æ—Ö–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏.]        []        99   \n",
       "\n",
       "       dataset_source                                              label  \n",
       "0    RUParusDatasetV1                              –°–æ–ª–Ω—Ü–µ —É–∂–µ –ø–æ–¥–Ω—è–ª–æ—Å—å.  \n",
       "1    RUParusDatasetV1  –ñ–µ–Ω—â–∏–Ω–∞ –∑–Ω–∞–ª–∞, —á—Ç–æ –µ—ë –ø–æ–¥—Ä—É–≥–∞ –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç —Ç—Ä—É–¥–Ω...  \n",
       "2    RUParusDatasetV1              –ò–º —Ö–æ—Ç–µ–ª–æ—Å—å –ø–µ—Ä–µ—Å–µ—á—å—Å—è –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º.  \n",
       "3    RUParusDatasetV1                –ü—Ä–æ–≥–Ω–æ–∑ –æ–±–µ—â–∞–ª –≤—ã—Å–æ–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É.  \n",
       "4    RUParusDatasetV1                        –≠—Ç–æ –±—ã–ª–∞ –≤–µ—á–µ—Ä–∏–Ω–∫–∞-—Å—é—Ä–ø—Ä–∏–∑.  \n",
       "..                ...                                                ...  \n",
       "495  RUParusDatasetV1                                –Ø —Ö–æ–¥–∏–ª –Ω–∞ –∫–æ–Ω—Ü–µ—Ä—Ç.  \n",
       "496  RUParusDatasetV1                                    –Ø –∂–¥–∞–ª–∞ –¥—Ä—É–∑–µ–π.  \n",
       "497  RUParusDatasetV1                    –û–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –º–Ω–µ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—é.  \n",
       "498  RUParusDatasetV1                                     –Ø –∫—É–ø–∏–ª –Ω–æ–≤—ã–π.  \n",
       "499  RUParusDatasetV1         –û–Ω–∞ –ø–æ–ø—Ä–æ—Å–∏–ª–∞ –ø–æ–¥—Ä—É–≥—É –æ—Å—Ç–∞–≤–∏—Ç—å –µ—ë –≤ –ø–æ–∫–æ–µ.  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_parus_dataloaders import RUParusDatasetV1\n",
    "dataset = RUParusDatasetV1(\n",
    "    input_dataset_path='./datasets/parus/parus.csv'\n",
    ")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# da_net_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"./datasets/da_net_qa/train.jsonl\"\n",
    "valid_path = \"./datasets/da_net_qa/val.jsonl\"\n",
    "\n",
    "train_dataset = pd.read_json(train_path, lines=True)\n",
    "valid_dataset = pd.read_json(valid_path, lines=True)\n",
    "dataset = pd.concat([train_dataset, valid_dataset], ignore_index=True)\n",
    "dataset.to_csv(\"./datasets/da_net_qa/da_net_qa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?</td>\n",
       "      <td>¬´–í—ãÃÅ—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä¬ª ‚Äî —Å—Ç–∞–Ω—Ü–∏—è –ú–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –º–æ–Ω...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?</td>\n",
       "      <td>–í—ãÃÅ—Å—Ç–∞–≤–∫–∞ –¥–æ—Å—Ç–∏–∂–µÃÅ–Ω–∏–π –Ω–∞—Ä–æÃÅ–¥–Ω–æ–≥–æ —Ö–æ–∑—èÃÅ–π—Å—Ç–≤–∞  ,...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ë—ã–ª –ª–∏ –¥–∂–∏–≥–∞–Ω –≤ black star?</td>\n",
       "      <td>–í–º–µ—Å—Ç–µ —Å —ç—Ç–∏–º —Ç—Ä–µ–∫–æ–º –æ–Ω–∏ –≤—ã—Å—Ç—É–ø–∏–ª–∏ –Ω–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiaomi –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç apple?</td>\n",
       "      <td>Xiaomi ‚Äî –∫–∏—Ç–∞–π—Å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –≤ 2010...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ë—ã–ª –ª–∏ –∞–≤—Ç–æ–º–∞—Ç –∫–∞–ª–∞—à–Ω–∏–∫–æ–≤–∞ –≤ –≤–æ–≤?</td>\n",
       "      <td>–û—Ç–º–µ—Ç–∏–≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∏ –≤ —Ü–µ–ª–æ–º —É–¥–∞—á–Ω—É—é...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  \\\n",
       "0      –í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?   \n",
       "1      –í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?   \n",
       "2        –ë—ã–ª –ª–∏ –¥–∂–∏–≥–∞–Ω –≤ black star?   \n",
       "3            Xiaomi –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç apple?   \n",
       "4  –ë—ã–ª –ª–∏ –∞–≤—Ç–æ–º–∞—Ç –∫–∞–ª–∞—à–Ω–∏–∫–æ–≤–∞ –≤ –≤–æ–≤?   \n",
       "\n",
       "                                             passage  label  idx  \n",
       "0  ¬´–í—ãÃÅ—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä¬ª ‚Äî —Å—Ç–∞–Ω—Ü–∏—è –ú–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –º–æ–Ω...   True    0  \n",
       "1  –í—ãÃÅ—Å—Ç–∞–≤–∫–∞ –¥–æ—Å—Ç–∏–∂–µÃÅ–Ω–∏–π –Ω–∞—Ä–æÃÅ–¥–Ω–æ–≥–æ —Ö–æ–∑—èÃÅ–π—Å—Ç–≤–∞  ,...   True    1  \n",
       "2  –í–º–µ—Å—Ç–µ —Å —ç—Ç–∏–º —Ç—Ä–µ–∫–æ–º –æ–Ω–∏ –≤—ã—Å—Ç—É–ø–∏–ª–∏ –Ω–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏...   True    2  \n",
       "3  Xiaomi ‚Äî –∫–∏—Ç–∞–π—Å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –≤ 2010...   True    3  \n",
       "4  –û—Ç–º–µ—Ç–∏–≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∏ –≤ —Ü–µ–ª–æ–º —É–¥–∞—á–Ω—É—é...  False    4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./datasets/da_net_qa/da_net_qa.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[–í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?]</td>\n",
       "      <td>[¬´–í—ãÃÅ—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä¬ª ‚Äî —Å—Ç–∞–Ω—Ü–∏—è –ú–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –º–æ...</td>\n",
       "      <td>0</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[–í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?]</td>\n",
       "      <td>[–í—ãÃÅ—Å—Ç–∞–≤–∫–∞ –¥–æ—Å—Ç–∏–∂–µÃÅ–Ω–∏–π –Ω–∞—Ä–æÃÅ–¥–Ω–æ–≥–æ —Ö–æ–∑—èÃÅ–π—Å—Ç–≤–∞  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[–ë—ã–ª –ª–∏ –¥–∂–∏–≥–∞–Ω –≤ black star?]</td>\n",
       "      <td>[–í–º–µ—Å—Ç–µ —Å —ç—Ç–∏–º —Ç—Ä–µ–∫–æ–º –æ–Ω–∏ –≤—ã—Å—Ç—É–ø–∏–ª–∏ –Ω–∞ —Ü–µ—Ä–µ–º–æ–Ω...</td>\n",
       "      <td>2</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Xiaomi –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç apple?]</td>\n",
       "      <td>[Xiaomi ‚Äî –∫–∏—Ç–∞–π—Å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –≤ 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[–ë—ã–ª –ª–∏ –∞–≤—Ç–æ–º–∞—Ç –∫–∞–ª–∞—à–Ω–∏–∫–æ–≤–∞ –≤ –≤–æ–≤?]</td>\n",
       "      <td>[–û—Ç–º–µ—Ç–∏–≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∏ –≤ —Ü–µ–ª–æ–º —É–¥–∞—á–Ω—É...</td>\n",
       "      <td>4</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–ù–µ—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>[–ñ–∏–≤–µ—Ç –ª–∏ –≤–ø—á –≤ –∫—Ä–æ–≤–∏?]</td>\n",
       "      <td>[–î–ù–ö –≤–∏—Ä—É—Å–∞ –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ –¥—É–±–ª–∏—Ä—É–µ—Ç –µ–≥–æ –±–µ–ª–∫–∏, —Ç...</td>\n",
       "      <td>2565</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–ù–µ—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>[–í—Ä–µ–¥–Ω–∞ –ª–∏ —Ñ–æ—Ç–æ—ç–ø–∏–ª—è—Ü–∏—è –≤ –¥–æ–º–∞—à–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö?]</td>\n",
       "      <td>[–ü—Ä–æ—è–≤–ª—è—é—Ç—Å—è –≤ –≤–∏–¥–µ –¥–µ—Ä–º–∞—Ç–∏—Ç–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º,...</td>\n",
       "      <td>2566</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>[–ë—ã–ª–∏ –ª–∏ –±–µ–∑–¥–µ—Ç–Ω—ã–º–∏ –º–∞—Ä–∏—è –∏ –∏–æ—Å–∏—Ñ?]</td>\n",
       "      <td>[–û –∂–∏–∑–Ω–∏ –µ–≥–æ, –∫—Ä–æ–º–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤ —Ä–æ–∂–¥–µ–Ω–∏—è –•—Ä–∏...</td>\n",
       "      <td>2567</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–ù–µ—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>[–ï—Å—Ç—å –ª–∏ —É –ª—É–Ω—ã —è–¥—Ä–æ?]</td>\n",
       "      <td>[–≠—Ç–æ –¥–≤–∏–∂–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ—Ü–µ—Å—Å–∏–æ–Ω–Ω—ã–º; –ø–æ–≤–æ—Ä–æ—Ç ...</td>\n",
       "      <td>2568</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>[–ë—ã–ª –ª–∏ –≤ —Å—Å—Å—Ä –Ω–∞–ª–æ–≥ –Ω–∞ –±–µ–∑–¥–µ—Ç–Ω–æ—Å—Ç—å?]</td>\n",
       "      <td>[–ù–∞–ª–æ–≥ –Ω–∞ –±–µ–∑–¥–µ—Ç–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª –≤ –°–°–°–† –∫–∞–∫ ¬´...</td>\n",
       "      <td>2569</td>\n",
       "      <td>RUDanetqaDatasetV1</td>\n",
       "      <td>–î–∞</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2570 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context  \\\n",
       "0                   [–í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?]   \n",
       "1                   [–í–¥–Ω—Ö - —ç—Ç–æ –≤—ã—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä?]   \n",
       "2                     [–ë—ã–ª –ª–∏ –¥–∂–∏–≥–∞–Ω –≤ black star?]   \n",
       "3                         [Xiaomi –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç apple?]   \n",
       "4               [–ë—ã–ª –ª–∏ –∞–≤—Ç–æ–º–∞—Ç –∫–∞–ª–∞—à–Ω–∏–∫–æ–≤–∞ –≤ –≤–æ–≤?]   \n",
       "...                                             ...   \n",
       "2565                        [–ñ–∏–≤–µ—Ç –ª–∏ –≤–ø—á –≤ –∫—Ä–æ–≤–∏?]   \n",
       "2566  [–í—Ä–µ–¥–Ω–∞ –ª–∏ —Ñ–æ—Ç–æ—ç–ø–∏–ª—è—Ü–∏—è –≤ –¥–æ–º–∞—à–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö?]   \n",
       "2567            [–ë—ã–ª–∏ –ª–∏ –±–µ–∑–¥–µ—Ç–Ω—ã–º–∏ –º–∞—Ä–∏—è –∏ –∏–æ—Å–∏—Ñ?]   \n",
       "2568                         [–ï—Å—Ç—å –ª–∏ —É –ª—É–Ω—ã —è–¥—Ä–æ?]   \n",
       "2569          [–ë—ã–ª –ª–∏ –≤ —Å—Å—Å—Ä –Ω–∞–ª–æ–≥ –Ω–∞ –±–µ–∑–¥–µ—Ç–Ω–æ—Å—Ç—å?]   \n",
       "\n",
       "                                              knowledge sample_id  \\\n",
       "0     [¬´–í—ãÃÅ—Å—Ç–∞–≤–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä¬ª ‚Äî —Å—Ç–∞–Ω—Ü–∏—è –ú–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –º–æ...         0   \n",
       "1     [–í—ãÃÅ—Å—Ç–∞–≤–∫–∞ –¥–æ—Å—Ç–∏–∂–µÃÅ–Ω–∏–π –Ω–∞—Ä–æÃÅ–¥–Ω–æ–≥–æ —Ö–æ–∑—èÃÅ–π—Å—Ç–≤–∞  ...         1   \n",
       "2     [–í–º–µ—Å—Ç–µ —Å —ç—Ç–∏–º —Ç—Ä–µ–∫–æ–º –æ–Ω–∏ –≤—ã—Å—Ç—É–ø–∏–ª–∏ –Ω–∞ —Ü–µ—Ä–µ–º–æ–Ω...         2   \n",
       "3     [Xiaomi ‚Äî –∫–∏—Ç–∞–π—Å–∫–∞—è –∫–æ–º–ø–∞–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –≤ 201...         3   \n",
       "4     [–û—Ç–º–µ—Ç–∏–≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∏ –≤ —Ü–µ–ª–æ–º —É–¥–∞—á–Ω—É...         4   \n",
       "...                                                 ...       ...   \n",
       "2565  [–î–ù–ö –≤–∏—Ä—É—Å–∞ –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ –¥—É–±–ª–∏—Ä—É–µ—Ç –µ–≥–æ –±–µ–ª–∫–∏, —Ç...      2565   \n",
       "2566  [–ü—Ä–æ—è–≤–ª—è—é—Ç—Å—è –≤ –≤–∏–¥–µ –¥–µ—Ä–º–∞—Ç–∏—Ç–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º,...      2566   \n",
       "2567  [–û –∂–∏–∑–Ω–∏ –µ–≥–æ, –∫—Ä–æ–º–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤ —Ä–æ–∂–¥–µ–Ω–∏—è –•—Ä–∏...      2567   \n",
       "2568  [–≠—Ç–æ –¥–≤–∏–∂–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ—Ü–µ—Å—Å–∏–æ–Ω–Ω—ã–º; –ø–æ–≤–æ—Ä–æ—Ç ...      2568   \n",
       "2569  [–ù–∞–ª–æ–≥ –Ω–∞ –±–µ–∑–¥–µ—Ç–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª –≤ –°–°–°–† –∫–∞–∫ ¬´...      2569   \n",
       "\n",
       "          dataset_source label  \n",
       "0     RUDanetqaDatasetV1    –î–∞  \n",
       "1     RUDanetqaDatasetV1    –î–∞  \n",
       "2     RUDanetqaDatasetV1    –î–∞  \n",
       "3     RUDanetqaDatasetV1    –î–∞  \n",
       "4     RUDanetqaDatasetV1   –ù–µ—Ç  \n",
       "...                  ...   ...  \n",
       "2565  RUDanetqaDatasetV1   –ù–µ—Ç  \n",
       "2566  RUDanetqaDatasetV1    –î–∞  \n",
       "2567  RUDanetqaDatasetV1   –ù–µ—Ç  \n",
       "2568  RUDanetqaDatasetV1    –î–∞  \n",
       "2569  RUDanetqaDatasetV1    –î–∞  \n",
       "\n",
       "[2570 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_danetqa_dataloaders import RUDanetqaDatasetV1\n",
    "\n",
    "dataset = RUDanetqaDatasetV1(\n",
    "\tinput_dataset_path='./datasets/da_net_qa/da_net_qa.csv'\n",
    ")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ru persona chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "      <th>history</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[–£ –º–µ–Ω—è –ª—é–±–∏–º–∞—è —Ä–∞–±–æ—Ç–∞., –Ø —É–≤–∞–∂–∞—é –ª—é–¥–µ–π., –£ –º–µ...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ., –ü—Ä–∏–≤–µ—Ç) –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π...</td>\n",
       "      <td>0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[–£ –º–µ–Ω—è –ª—é–±–∏–º–∞—è —Ä–∞–±–æ—Ç–∞., –Ø —É–≤–∞–∂–∞—é –ª—é–¥–µ–π., –£ –º–µ...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ., –ü—Ä–∏–≤–µ—Ç) –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π...</td>\n",
       "      <td>0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[–Ø –±–∏–∑–Ω–µ—Å–º–µ–Ω., –£ –º–µ–Ω—è —Å–∫–æ—Ä–æ —Å–≤–∞–¥—å–±–∞., –ú–µ–Ω—è –ª—é–±...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç!, –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å?]</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[–Ø –±–∏–∑–Ω–µ—Å–º–µ–Ω., –£ –º–µ–Ω—è —Å–∫–æ—Ä–æ —Å–≤–∞–¥—å–±–∞., –ú–µ–Ω—è –ª—é–±...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç!, –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å?, –û—Ç–ª–∏—á–Ω–æ) –°–æ–ª–Ω—ã—à–∫–æ...</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[–Ø –ø–æ—é –≤ –∫–∞—Ä–∞–æ–∫–µ., –£ –º–µ–Ω—è –µ—Å—Ç—å —Å—É–ø—Ä—É–≥–∞., –•–æ—Ä–æ—à...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç. –ö–∞–∫ –¥–µ–ª–∞ ?, –î–æ–±—Ä—ã–π –¥–µ–Ω—å! –•–æ—Ä–æ—à–æ,  —á–µ–º...</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67013</th>\n",
       "      <td>[–Ø –≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å., –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å., –ª—é–±–ª—é –≤–µ–ª–æ—Å–ø...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç–∏–∫), –ü—Ä–∏–≤–µ—Ç. –ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è), –ö–∞–∫ –¥–µ–ª...</td>\n",
       "      <td>10011_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67014</th>\n",
       "      <td>[–Ø –≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å., –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å., –ª—é–±–ª—é –≤–µ–ª–æ—Å–ø...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç–∏–∫), –ü—Ä–∏–≤–µ—Ç. –ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è), –ö–∞–∫ –¥–µ–ª...</td>\n",
       "      <td>10011_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67015</th>\n",
       "      <td>[–Ø –∂–µ–Ω–∞—Ç., –õ—é–±–ª—é —Å–≤–æ—é –∂–µ–Ω—É., –†–∞–±–æ—Ç–∞—é –ø—Ä–æ—Ä–∞–±–æ–º ...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞...</td>\n",
       "      <td>10012_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67016</th>\n",
       "      <td>[–Ø –∂–µ–Ω–∞—Ç., –õ—é–±–ª—é —Å–≤–æ—é –∂–µ–Ω—É., –†–∞–±–æ—Ç–∞—é –ø—Ä–æ—Ä–∞–±–æ–º ...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞...</td>\n",
       "      <td>10012_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67017</th>\n",
       "      <td>[–Ø –∂–µ–Ω–∞—Ç., –õ—é–±–ª—é —Å–≤–æ—é –∂–µ–Ω—É., –†–∞–±–æ—Ç–∞—é –ø—Ä–æ—Ä–∞–±–æ–º ...</td>\n",
       "      <td>[–ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞...</td>\n",
       "      <td>10012_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67018 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 persona  \\\n",
       "0      [–£ –º–µ–Ω—è –ª—é–±–∏–º–∞—è —Ä–∞–±–æ—Ç–∞., –Ø —É–≤–∞–∂–∞—é –ª—é–¥–µ–π., –£ –º–µ...   \n",
       "1      [–£ –º–µ–Ω—è –ª—é–±–∏–º–∞—è —Ä–∞–±–æ—Ç–∞., –Ø —É–≤–∞–∂–∞—é –ª—é–¥–µ–π., –£ –º–µ...   \n",
       "2      [–Ø –±–∏–∑–Ω–µ—Å–º–µ–Ω., –£ –º–µ–Ω—è —Å–∫–æ—Ä–æ —Å–≤–∞–¥—å–±–∞., –ú–µ–Ω—è –ª—é–±...   \n",
       "3      [–Ø –±–∏–∑–Ω–µ—Å–º–µ–Ω., –£ –º–µ–Ω—è —Å–∫–æ—Ä–æ —Å–≤–∞–¥—å–±–∞., –ú–µ–Ω—è –ª—é–±...   \n",
       "4      [–Ø –ø–æ—é –≤ –∫–∞—Ä–∞–æ–∫–µ., –£ –º–µ–Ω—è –µ—Å—Ç—å —Å—É–ø—Ä—É–≥–∞., –•–æ—Ä–æ—à...   \n",
       "...                                                  ...   \n",
       "67013  [–Ø –≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å., –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å., –ª—é–±–ª—é –≤–µ–ª–æ—Å–ø...   \n",
       "67014  [–Ø –≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å., –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å., –ª—é–±–ª—é –≤–µ–ª–æ—Å–ø...   \n",
       "67015  [–Ø –∂–µ–Ω–∞—Ç., –õ—é–±–ª—é —Å–≤–æ—é –∂–µ–Ω—É., –†–∞–±–æ—Ç–∞—é –ø—Ä–æ—Ä–∞–±–æ–º ...   \n",
       "67016  [–Ø –∂–µ–Ω–∞—Ç., –õ—é–±–ª—é —Å–≤–æ—é –∂–µ–Ω—É., –†–∞–±–æ—Ç–∞—é –ø—Ä–æ—Ä–∞–±–æ–º ...   \n",
       "67017  [–Ø –∂–µ–Ω–∞—Ç., –õ—é–±–ª—é —Å–≤–æ—é –∂–µ–Ω—É., –†–∞–±–æ—Ç–∞—é –ø—Ä–æ—Ä–∞–±–æ–º ...   \n",
       "\n",
       "                                                 history sample_id  \n",
       "0      [–ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ., –ü—Ä–∏–≤–µ—Ç) –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π...       0_1  \n",
       "1      [–ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ., –ü—Ä–∏–≤–µ—Ç) –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π...       0_2  \n",
       "2                           [–ü—Ä–∏–≤–µ—Ç!, –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å?]       1_1  \n",
       "3      [–ü—Ä–∏–≤–µ—Ç!, –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å?, –û—Ç–ª–∏—á–Ω–æ) –°–æ–ª–Ω—ã—à–∫–æ...       1_2  \n",
       "4      [–ü—Ä–∏–≤–µ—Ç. –ö–∞–∫ –¥–µ–ª–∞ ?, –î–æ–±—Ä—ã–π –¥–µ–Ω—å! –•–æ—Ä–æ—à–æ,  —á–µ–º...       2_1  \n",
       "...                                                  ...       ...  \n",
       "67013  [–ü—Ä–∏–≤–µ—Ç–∏–∫), –ü—Ä–∏–≤–µ—Ç. –ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è), –ö–∞–∫ –¥–µ–ª...   10011_4  \n",
       "67014  [–ü—Ä–∏–≤–µ—Ç–∏–∫), –ü—Ä–∏–≤–µ—Ç. –ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è), –ö–∞–∫ –¥–µ–ª...   10011_5  \n",
       "67015  [–ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞...   10012_1  \n",
       "67016  [–ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞...   10012_2  \n",
       "67017  [–ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞...   10012_3  \n",
       "\n",
       "[67018 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dimweb_persona_bot.dataloaders.ru_persona_chat_dataloaders import RUPersonaChatDatasetV3\n",
    "\n",
    "dataset = RUPersonaChatDatasetV3(\n",
    "\tinput_dataset_path='./datasets/ru_persona_chat/dialogues.tsv'\n",
    ")\n",
    "dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 2022\n",
    "# [cornell_movie_corpus]\n",
    "# [ru_persona_chat]\n",
    "# [ru_anekdots_dialogs]\n",
    "# [ru_flibusta_dialogues]\n",
    "# [ru_rubq20]\n",
    "# [ru_danetqa]\n",
    "# [ru_parus]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cornell_movie_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50592, 512)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1 = \"./datasets/cornell_movie_corpus/cornell_movie_corpus.txt\"\n",
    "dataset = open(data_path_1, \"r\", encoding=\"utf-8\").read().split(\"\\n\\n\\n\\n\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "\n",
    "open(\"./datasets/cornell_movie_corpus/cornell_movie_corpus_train.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(train))\n",
    "open(\"./datasets/cornell_movie_corpus/cornell_movie_corpus_test.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(test))\n",
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_persona_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9912, 101)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/ru_persona_chat/dialogues.tsv\", sep=\"\\t\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "train.to_csv(\"./datasets/ru_persona_chat/ru_persona_chat_train.tsv\", sep=\"\\t\", index=False)\n",
    "test.to_csv(\"./datasets/ru_persona_chat/ru_persona_chat_test.tsv\", sep=\"\\t\", index=False)\n",
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_anekdots_dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86843, 878)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1 = \"./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs.txt\"\n",
    "dataset = open(data_path_1, \"r\", encoding=\"utf-8\").read().split(\"\\n\\n\\n\\n\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "open(\"./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_train.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(train))\n",
    "open(\"./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_test.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(test))\n",
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_flibusta_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3268703, 33018)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1 = \"./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues.txt\"\n",
    "dataset = open(data_path_1, \"r\", encoding=\"utf-8\").read().split(\"\\n\\n\\n\\n\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "open(\"./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_train.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(train))\n",
    "open(\"./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_test.txt\", \"w\", encoding=\"utf-8\").write(\"\\n\\n\\n\\n\".join(test))\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_rubq20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 30, 56952)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data_dev = open('./datasets/ru_rubq20/RuBQ_2.0_dev.json', 'r',) \n",
    "data_dev = json.load(data_dev)\n",
    "\n",
    "data_test = open('./datasets/ru_rubq20/RuBQ_2.0_test.json', 'r')\n",
    "data_test = json.load(data_test)\n",
    "\n",
    "data_paragraphs = open('./datasets/ru_rubq20/RuBQ_2.0_paragraphs.json', 'r')\n",
    "data_paragraphs = json.load(data_paragraphs)\n",
    "data_paragraphs = {item['uid']: item for item in data_paragraphs}\n",
    "\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "all_questions = data_dev + data_test\n",
    "train_questions, test_questions = train_test_split(all_questions, test_size=0.01, random_state=RANDOM_SEED)\n",
    "\n",
    "train_data['questions'] = train_questions\n",
    "train_data['paragraphs'] = data_paragraphs\n",
    "test_data['paragraphs'] = data_paragraphs\n",
    "test_data['questions'] = test_questions\n",
    "\n",
    "with open('./datasets/ru_rubq20/ru_rubq20_train.json', 'w', encoding='utf-8') as outfile:\n",
    "\tjson.dump(train_data, outfile)\n",
    " \n",
    "with open('./datasets/ru_rubq20/ru_rubq20_test.json', 'w', encoding='utf-8') as outfile:\n",
    "\tjson.dump(test_data, outfile)\n",
    "\n",
    "len(train_questions), len(test_questions), len(data_paragraphs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_danetqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/ru_danetqa/ru_danetqa.csv\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "train.to_csv(\"./datasets/ru_danetqa/ru_danetqa_train.csv\", index=False)\n",
    "test.to_csv(\"./datasets/ru_danetqa/ru_danetqa_test.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ru_parus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"./datasets/ru_parus/ru_parus.csv\")\n",
    "train, test = train_test_split(dataset, test_size=0.01, random_state=RANDOM_SEED)\n",
    "train.to_csv(\"./datasets/ru_parus/ru_parus_train.csv\", index=False)\n",
    "test.to_csv(\"./datasets/ru_parus/ru_parus_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ru_persona_chat]\n",
    "# [cornell_movie_corpus]\n",
    "# [ru_anekdots_dialogs]\n",
    "# [flibusta_dialogues]\n",
    "# [RuBQ_2.0]\n",
    "# [da_net_qa]\n",
    "# [parus]\n",
    "\n",
    "from dimweb_persona_bot.dataloaders.ru_persona_chat_dataloaders import RUPersonaChatDatasetV3\n",
    "from dimweb_persona_bot.dataloaders.ru_cornel_movie_corpus_dataloaders import RUCornellMovieCorpusDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_anekdots_dialogs_dataloaders import RUAnekdotsDialogsDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_flibusta_dialogs_dataloaders import RUFlibustaDialogsDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_rubq20_dataloaders import RURubq20DatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_danetqa_dataloaders import RUDanetqaDatasetV1\n",
    "from dimweb_persona_bot.dataloaders.ru_parus_dataloaders import RUParusDatasetV1\n",
    "\n",
    "dataset_paths = [\n",
    "    {\n",
    "        \"data_path\": \"ru_persona_chat\",\n",
    "        \"dataset_class\": RUPersonaChatDatasetV3,\n",
    "        # tsv\n",
    "          \"extension\": \"tsv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_cornell_movie_corpus\",\n",
    "        \"dataset_class\": RUCornellMovieCorpusDatasetV1,\n",
    "        # txt\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_anekdots_dialogs\",\n",
    "        \"dataset_class\": RUAnekdotsDialogsDatasetV1,\n",
    "        # txt\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_flibusta_dialogues\",\n",
    "        \"dataset_class\": RUFlibustaDialogsDatasetV1,\n",
    "        # txt\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_rubq20\",\n",
    "        \"dataset_class\": RURubq20DatasetV1,\n",
    "        # json\n",
    "        \"extension\": \"json\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_danetqa\",\n",
    "        \"dataset_class\": RUDanetqaDatasetV1,\n",
    "        # csv\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_parus\",\n",
    "        \"dataset_class\": RUParusDatasetV1,\n",
    "        # csv\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_persona_chat/ru_persona_chat_train.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912/9912 [00:27<00:00, 366.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_persona_chat/ru_persona_chat_test.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:00<00:00, 387.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_cornell_movie_corpus/ru_cornell_movie_corpus_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50592it [00:00, 97198.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_cornell_movie_corpus/ru_cornell_movie_corpus_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [00:00, 139474.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "86843it [00:00, 110921.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_anekdots_dialogs/ru_anekdots_dialogs_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [00:00, 148103.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3268703it [00:23, 137478.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_flibusta_dialogues/ru_flibusta_dialogues_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33018it [00:00, 177105.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_rubq20/ru_rubq20_train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2880it [00:00, 47474.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_rubq20/ru_rubq20_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:00, 109416.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_danetqa/ru_danetqa_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2544/2544 [00:00<00:00, 11206.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_danetqa/ru_danetqa_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:00<00:00, 10355.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_parus/ru_parus_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 495/495 [00:00<00:00, 9644.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/ru_parus/ru_parus_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 6846.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# 1 min 30 sec\n",
    "for dataset_path in dataset_paths:\n",
    "    extension = dataset_path['extension']\n",
    "    for status in ['train', 'test']:\n",
    "        path = dataset_path['data_path']\n",
    "        full_path = f\"./datasets/{path}/{path}_{status}.{extension}\"\n",
    "        seq2seq_path_csv = f\"./datasets/{path}/seq2seq_{status}.csv\"\n",
    "        seq2seq_path_parquet = f\"./datasets/{path}/seq2seq_{status}.parquet\"\n",
    "        print(full_path)\n",
    "        dataset = dataset_path['dataset_class'](\n",
    "            input_dataset_path=full_path\n",
    "        )\n",
    "        dataset = dataset.to_pandas()\n",
    "        dataset.to_csv(seq2seq_path_csv, index=False)\n",
    "        dataset.to_parquet(seq2seq_path_parquet, index=False)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# for dataset_path in dataset_paths:\n",
    "#     extension = dataset_path['extension']\n",
    "#     for status in ['train', 'test']:\n",
    "#         path = dataset_path['data_path']\n",
    "#         seq2seq_path_csv = f\"./datasets/{path}/seq2seq_{status}.csv\"\n",
    "#         seq2seq_path_parquet = f\"./datasets/{path}/seq2seq_{status}.parquet\"\n",
    "        \n",
    "#         dataset = pd.read_csv(seq2seq_path_csv)\n",
    "#         dataset.to_parquet(seq2seq_path_parquet, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# huggigface datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/ru_persona_chat/seq2seq_test.parquet',\n",
       " './datasets/ru_cornell_movie_corpus/seq2seq_test.parquet',\n",
       " './datasets/ru_anekdots_dialogs/seq2seq_test.parquet',\n",
       " './datasets/ru_flibusta_dialogues/seq2seq_test.parquet',\n",
       " './datasets/ru_rubq20/seq2seq_test.parquet',\n",
       " './datasets/ru_danetqa/seq2seq_test.parquet',\n",
       " './datasets/ru_parus/seq2seq_test.parquet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paths = [\n",
    "    {\n",
    "        \"data_path\": \"ru_persona_chat\",\n",
    "        \"extension\": \"tsv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_cornell_movie_corpus\",\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_anekdots_dialogs\",\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_flibusta_dialogues\",\n",
    "        \"extension\": \"txt\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_rubq20\",\n",
    "        \"extension\": \"json\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_danetqa\",\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "    {\n",
    "        \"data_path\": \"ru_parus\",\n",
    "        \"extension\": \"csv\"\n",
    "    },\n",
    "]\n",
    "\n",
    "train_parquet_paths = []\n",
    "test_parquet_paths = []\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "    extension = dataset_path['extension']\n",
    "    for status in ['train', 'test']:\n",
    "        path = dataset_path['data_path']\n",
    "        seq2seq_path_parquet = f\"./datasets/{path}/seq2seq_{status}.parquet\"\n",
    "        if status == 'train':\n",
    "            train_parquet_paths.append(seq2seq_path_parquet)\n",
    "        else:\n",
    "            test_parquet_paths.append(seq2seq_path_parquet)\n",
    "test_parquet_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-fe2f19362784e9e0\n",
      "Reusing dataset parquet (/home/kosenko/.cache/huggingface/datasets/parquet/default-fe2f19362784e9e0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c827a128b784fbc90e296b34e86a423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    \"parquet\", \n",
    "    data_files={\n",
    "        'train': train_parquet_paths, \n",
    "        'test': test_parquet_paths\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 653.98 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Process.memory_info is expressed in bytes, so convert to megabytes\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'knowledge', 'dataset_source', 'label', 'sample_id'],\n",
       "        num_rows: 5100110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'knowledge', 'dataset_source', 'label', 'sample_id'],\n",
       "        num_rows: 51225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '<c> –ü—Ä–∏–≤–µ—Ç –ø—Ä–∏–≤–µ—Ç ! –ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ ? –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è ?',\n",
       " 'knowledge': ' <k> –Ø —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ. <s> –£ –º–µ–Ω—è –µ—Å—Ç—å —Å–æ–±–∞–∫–∞. <s> –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å. <s> –Ø –ª—é–±–ª—é —à–æ–∫–æ–ª–∞–¥. <s> –Ø —Å–ª—É—à–∞—é –ø–æ–ø-—Ä–æ–∫.',\n",
       " 'dataset_source': 'RUPersonaChatDatasetV3',\n",
       " 'label': '–ü—Ä–∏–≤–µ—Ç! –Ø —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ. –ê —Ç—ã?',\n",
       " 'sample_id': 'RUPersonaChatDatasetV3_0_1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50\")\n",
    "\n",
    "def text_lens(example):\n",
    "    context = tokenizer.batch_encode_plus(example['context'])\n",
    "    context = [len(item) for item in context['input_ids']]\n",
    "    \n",
    "    knowledge = tokenizer.batch_encode_plus(example['knowledge'])\n",
    "    knowledge = [len(item) for item in knowledge['input_ids']]\n",
    "    \n",
    "    labels = tokenizer.batch_encode_plus(example['label'])\n",
    "    labels = [len(item) for item in labels['input_ids']]\n",
    "    \n",
    "    return {\n",
    "        \"context_len\": context,\n",
    "        \"knowledge_len\": knowledge,\n",
    "        \"label_len\": labels\n",
    "    }\n",
    "\n",
    "def process_dataset(example):\n",
    "    context = tokenizer.batch_encode_plus(\n",
    "        example['context'],\n",
    "        truncation=True,\n",
    "        max_length=479,\n",
    "    )\n",
    "    knowledge = tokenizer.batch_encode_plus(\n",
    "        example['knowledge'],\n",
    "        truncation=True,\n",
    "        max_length=522,\n",
    "    )\n",
    "    labels = tokenizer.batch_encode_plus(\n",
    "        example['label'],\n",
    "        truncation=True,\n",
    "        max_length=333,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    input_ids = []\n",
    "    next_prefix = tokenizer.encode(' => ')\n",
    "    \n",
    "    for con_ids, con_attn, know_ids, know_attn in zip(\n",
    "        context['input_ids'], \n",
    "        context['attention_mask'], \n",
    "        knowledge['input_ids'], \n",
    "        knowledge['attention_mask']):\n",
    "        new_input_ids = con_ids + know_ids + next_prefix\n",
    "        \n",
    "        input_ids.append(new_input_ids)\n",
    "    \n",
    "    input_ids = tokenizer.batch_decode(input_ids)\n",
    "    input_ids = tokenizer.batch_encode_plus(\n",
    "        input_ids,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    labels = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "        \n",
    "    return {\n",
    "        \"input_ids\": input_ids['input_ids'],\n",
    "        \"attention_mask\": input_ids['attention_mask'],\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n",
      "                  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5bd23510044549a10d13c316cdcb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46096f635b884d8ea60f30ca99a3b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f711ad01c9d43d6a1893cb5e3747ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809c68568e57412fa20569d0c1356da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e8a3527c644283b7adeeb358b540c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0525acd48c384b17a0e498d690d0d3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b066c96a10514c82a07f849139234e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc0a0708b3141a6baf6c188c7cfb33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe7de483db8486f92ddf1e1728216db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e52d11c937e4e71b861c72abfc20e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad65f3debb064a1fb6e7e91402e8bdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2e4a445fa14d94afd5d8a49e7c7888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2948f33f057f4b27881be5b75af83de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0047dcb5ac94fdeaffb9ab229758ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9acfa7035e4e2ba212c0082eb392e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df5d3e706ee4b47b107afd9a9ebd52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Error writing bytes to file. Detail: [errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_dataset.py\", line 2792, in _map_single\n    writer.write_batch(batch)\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_writer.py\", line 512, in write_batch\n    self.write_table(pa_table, writer_batch_size)\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_writer.py\", line 529, in write_table\n    self.pa_writer.write_batch(batch)\n  File \"pyarrow/ipc.pxi\", line 484, in pyarrow.lib._CRecordBatchWriter.write_batch\n  File \"pyarrow/error.pxi\", line 113, in pyarrow.lib.check_status\nOSError: [Errno 122] Error writing bytes to file. Detail: [errno 122] Disk quota exceeded\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/kosenko/env/lib/python3.8/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_dataset.py\", line 557, in wrapper\n    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_dataset.py\", line 524, in wrapper\n    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/fingerprint.py\", line 480, in wrapper\n    out = func(self, *args, **kwargs)\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_dataset.py\", line 2798, in _map_single\n    writer.finalize()\n  File \"/home/kosenko/env/lib/python3.8/site-packages/datasets/arrow_writer.py\", line 544, in finalize\n    self.pa_writer.close()\n  File \"pyarrow/ipc.pxi\", line 514, in pyarrow.lib._CRecordBatchWriter.close\n  File \"pyarrow/error.pxi\", line 113, in pyarrow.lib.check_status\nOSError: [Errno 122] Error writing bytes to file. Detail: [errno 122] Disk quota exceeded\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m      2\u001b[0m     process_dataset, \n\u001b[1;32m      3\u001b[0m     batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      4\u001b[0m     num_proc\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,   \n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/datasets/dataset_dict.py:770\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 770\u001b[0m     {\n\u001b[1;32m    771\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m    772\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[1;32m    773\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[1;32m    774\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[1;32m    775\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[1;32m    776\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[1;32m    777\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    778\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    779\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[1;32m    780\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    781\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    782\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    783\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    784\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    785\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[1;32m    786\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[1;32m    787\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m    788\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[1;32m    789\u001b[0m         )\n\u001b[1;32m    790\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    791\u001b[0m     }\n\u001b[1;32m    792\u001b[0m )\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/datasets/dataset_dict.py:771\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    770\u001b[0m     {\n\u001b[0;32m--> 771\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    772\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    773\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m    774\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m    775\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m    776\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    777\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    778\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m    779\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m    780\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m    781\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m    782\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[1;32m    783\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m    784\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    785\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m    786\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m    787\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    788\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m    789\u001b[0m         )\n\u001b[1;32m    790\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    791\u001b[0m     }\n\u001b[1;32m    792\u001b[0m )\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/datasets/arrow_dataset.py:2500\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2495\u001b[0m         \u001b[39massert\u001b[39;00m (\n\u001b[1;32m   2496\u001b[0m             \u001b[39mlen\u001b[39m(results) \u001b[39m==\u001b[39m nb_of_missing_shards\n\u001b[1;32m   2497\u001b[0m         ), \u001b[39m\"\u001b[39m\u001b[39mThe number of missing cached shards needs to correspond to the number of `_map_single` we\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre running\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2499\u001b[0m         \u001b[39mfor\u001b[39;00m index, async_result \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mitems():\n\u001b[0;32m-> 2500\u001b[0m             transformed_shards[index] \u001b[39m=\u001b[39m async_result\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m   2502\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m   2503\u001b[0m     transformed_shards\u001b[39m.\u001b[39mcount(\u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   2504\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39mAll shards have to be defined Datasets, none should still be missing.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2506\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConcatenating \u001b[39m\u001b[39m{\u001b[39;00mnum_proc\u001b[39m}\u001b[39;00m\u001b[39m shards\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/multiprocess/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Error writing bytes to file. Detail: [errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    process_dataset, \n",
    "    batched=True,\n",
    "    num_proc=16,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(\"./datasets/ru_dialog_dataset_v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479.99890999961644"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "context_len = np.percentile(np.array(dataset['train']['context_len']), 99.999)\n",
    "context_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_len = np.percentile(np.array(dataset['train']['knowledge_len']), 99.9995)\n",
    "knowledge_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001.9989099996164"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_len+knowledge_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333.42992370016873"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array(dataset['train']['label_len']), 99.99999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afbd04eaf482342bd8c806741887bf29b8900f429828e19eaba1f287fa9febed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
